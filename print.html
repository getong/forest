<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">User Guide</li><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="basic_usage.html"><strong aria-hidden="true">1.1.</strong> Basic Usage</a></li><li class="chapter-item expanded "><a href="cli.html"><strong aria-hidden="true">1.2.</strong> Command-line interface</a></li><li class="chapter-item expanded "><a href="wallet.html"><strong aria-hidden="true">1.3.</strong> Wallet handling</a></li><li class="chapter-item expanded "><a href="configuration.html"><strong aria-hidden="true">1.4.</strong> Configuration</a></li><li class="chapter-item expanded "><a href="environment_variables.html"><strong aria-hidden="true">1.5.</strong> Environment Variables</a></li><li class="chapter-item expanded "><a href="docker.html"><strong aria-hidden="true">1.6.</strong> Docker</a></li><li class="chapter-item expanded "><a href="healthcheck.html"><strong aria-hidden="true">1.7.</strong> Healthcheck</a></li><li class="chapter-item expanded "><a href="snapshot_export.html"><strong aria-hidden="true">1.8.</strong> Snapshot exporting</a></li><li class="chapter-item expanded "><a href="jsonrpc.html"><strong aria-hidden="true">1.9.</strong> JSON-RPC API</a></li><li class="chapter-item expanded "><a href="backups.html"><strong aria-hidden="true">1.10.</strong> Backups</a></li><li class="chapter-item expanded "><a href="trouble_shooting.html"><strong aria-hidden="true">1.11.</strong> Troubleshooting</a></li><li class="chapter-item expanded "><a href="glossary.html"><strong aria-hidden="true">1.12.</strong> Glossary</a></li><li class="chapter-item expanded "><a href="bootstrap_node.html"><strong aria-hidden="true">1.13.</strong> Bootstrap node</a></li><li class="chapter-item expanded "><a href="offline-forest.html"><strong aria-hidden="true">1.14.</strong> Offline Forest</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Developer documentation</li><li class="chapter-item expanded "><a href="developer_documentation/introduction.html"><strong aria-hidden="true">2.</strong> Developer documentation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="developer_documentation/application_architecture.html"><strong aria-hidden="true">2.1.</strong> Application architecture</a></li><li class="chapter-item expanded "><a href="developer_documentation/contributing.html"><strong aria-hidden="true">2.2.</strong> Contributing</a></li><li class="chapter-item expanded "><a href="developer_documentation/database_migrations.html"><strong aria-hidden="true">2.3.</strong> Database migrations</a></li><li class="chapter-item expanded "><a href="developer_documentation/local_actions.html"><strong aria-hidden="true">2.4.</strong> Local GH Actions</a></li><li class="chapter-item expanded "><a href="developer_documentation/mainnet_compatibility.html"><strong aria-hidden="true">2.5.</strong> Mainnet compatibility</a></li><li class="chapter-item expanded "><a href="developer_documentation/memory-analysis.html"><strong aria-hidden="true">2.6.</strong> Memory analysis</a></li><li class="chapter-item expanded "><a href="developer_documentation/release_checklist.html"><strong aria-hidden="true">2.7.</strong> Release checklist</a></li><li class="chapter-item expanded "><a href="developer_documentation/state_migration.html"><strong aria-hidden="true">2.8.</strong> State migration</a></li><li class="chapter-item expanded "><a href="developer_documentation/state_migration_guide.html"><strong aria-hidden="true">2.9.</strong> State migration guide</a></li><li class="chapter-item expanded "><a href="developer_documentation/state_migration_spike.html"><strong aria-hidden="true">2.10.</strong> State migration spike NV17-NV18</a></li><li class="chapter-item expanded "><a href="developer_documentation/test_plan.html"><strong aria-hidden="true">2.11.</strong> Test plan</a></li><li class="chapter-item expanded "><a href="developer_documentation/devnet_notes.html"><strong aria-hidden="true">2.12.</strong> Devnet Notes</a></li><li class="chapter-item expanded "><a href="developer_documentation/archie_and_fuzzy.html"><strong aria-hidden="true">2.13.</strong> Archie and Fuzzy</a></li><li class="chapter-item expanded "><a href="developer_documentation/rpc_api_compatibility.html"><strong aria-hidden="true">2.14.</strong> RPC API Compatibility</a></li><li class="chapter-item expanded "><a href="developer_documentation/notes_and_sketches.html"><strong aria-hidden="true">2.15.</strong> Notes and sketches</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="developer_documentation/chain_muxer_state_machine.html"><strong aria-hidden="true">2.15.1.</strong> ChainMuxer/TipsetProcessor state machine</a></li></ol></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p align="center">
    <img height="269" src="./img/forest_logo.png">
</p>
<p align="center">
    <a href="https://github.com/ChainSafe/forest/actions"><img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/ChainSafe/forest/forest.yml?style=for-the-badge"></a>
    <a href="https://github.com/ChainSafe/forest/releases/latest"><img alt="Latest release" src="https://img.shields.io/github/v/release/ChainSafe/forest?style=for-the-badge"></a>
    <a href="https://docs.forest.chainsafe.io"><img alt="Docs" src="https://img.shields.io/badge/doc-user_guide-green?style=for-the-badge"></a>
    <a href="https://docs.forest.chainsafe.io/rustdoc/"><img alt="Rust Docs" src="https://img.shields.io/badge/doc-rust_docs-green?style=for-the-badge"></a>
</p>
 <p align="center">
    <a href="https://github.com/ChainSafe/forest/blob/main/LICENSE-APACHE"><img alt="License Apache 2.0" src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=for-the-badge"></a>
    <a href="https://github.com/ChainSafe/forest/blob/main/LICENSE-MIT"><img alt="License MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge"></a>
    <a href="https://discord.gg/Q6A3YA2"><img alt="Discord" src="https://img.shields.io/discord/593655374469660673.svg?style=for-the-badge&label=Discord&logo=discord"></a>
    <a href="https://twitter.com/ChainSafeth"><img alt="Twitter" src="https://img.shields.io/twitter/follow/chainsafeth?style=for-the-badge&color=1DA1F2"></a>
</p>
<p>Forest is an implementation of <a href="https://filecoin.io/">Filecoin</a> written in Rust.
The implementation takes a modular approach to building a full Filecoin node in
two parts — (i) building Filecoin’s security critical systems in Rust from the
<a href="https://filecoin-project.github.io/specs/">Filecoin Protocol Specification</a>,
specifically the virtual machine, blockchain, and node system, and (ii)
integrating functional components for storage mining and storage &amp; retrieval
markets to compose a fully functional Filecoin node implementation.</p>
<h2 id="functionality"><a class="header" href="#functionality">Functionality</a></h2>
<ul>
<li>Filecoin State Tree Synchronization</li>
<li>Filecoin JSON-RPC Server</li>
<li>Ergonomic Message Pool</li>
<li>Wallet CLI</li>
<li>Process Metrics &amp; Monitoring</li>
</ul>
<h2 id="disclaimer"><a class="header" href="#disclaimer">Disclaimer</a></h2>
<p>The Forest implementation of the Filecoin protocol is alpha software which
should not yet be integrated into production workflows. The team is working to
provide reliable, secure, and efficient interfaces to the Filecoin ecosystem. If
you would like to chat, please reach out over Discord on the ChainSafe server
linked above.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h1>
<h2 id="installation-with-pre-built-binaries"><a class="header" href="#installation-with-pre-built-binaries">Installation with pre-built binaries</a></h2>
<p>To install Forest from pre-compiled binaries, please refer to the
<a href="https://github.com/ChainSafe/forest/releases">releases page</a> or consider using
Forest Docker image (explained in detail <a href="docker.html">here</a>).</p>
<h2 id="installation-from-source"><a class="header" href="#installation-from-source">Installation from source</a></h2>
<h3 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h3>
<ul>
<li>Rust - install via <a href="https://rustup.rs/">rustup</a></li>
<li>OS Base-Devel/Build-Essential</li>
<li>Clang compiler</li>
</ul>
<p>For Ubuntu, you can install the dependencies (excluding Rust) with:</p>
<pre><code class="language-shell">sudo apt install build-essential clang
</code></pre>
<h3 id="compilation--installation"><a class="header" href="#compilation--installation">Compilation &amp; installation</a></h3>
<h4 id="from-cratesio-latest-release"><a class="header" href="#from-cratesio-latest-release">From crates.io (latest release)</a></h4>
<pre><code class="language-shell">cargo install forest-filecoin
</code></pre>
<h4 id="from-repository-latest-development-branch"><a class="header" href="#from-repository-latest-development-branch">From repository (latest development branch)</a></h4>
<pre><code class="language-shell"># Clone the Forest repository
git clone --depth 1 https://github.com/ChainSafe/forest.git &amp;&amp; cd forest
make install
</code></pre>
<p>Both approaches will compile and install <code>forest</code> and <code>forest-cli</code> to
<code>~/.cargo/bin</code>. Make sure you have it in your <code>PATH</code>.</p>
<h2 id="verifying-the-installation"><a class="header" href="#verifying-the-installation">Verifying the installation</a></h2>
<p>Ensure that Forest was correctly installed.</p>
<pre><code class="language-shell">forest --version
# forest-filecoin 0.10.0+git.2eaeb9fee
</code></pre>
<h2 id="synchronize-to-the-filecoin-network"><a class="header" href="#synchronize-to-the-filecoin-network">Synchronize to the Filecoin network</a></h2>
<p>Start the <code>forest</code> node. It will automatically connect to the bootstrap peers
and start syncing the chain after the snapshot is downloaded. If it is your
first time running the node, it will take a while to download the snapshot. Note
that you will need at least 8GB of RAM to sync the mainnet chain, and over 100
GB of free disk space.</p>
<h4 id="mainnet"><a class="header" href="#mainnet">Mainnet</a></h4>
<pre><code class="language-shell">forest
</code></pre>
<h4 id="calibnet"><a class="header" href="#calibnet">Calibnet</a></h4>
<pre><code class="language-shell">forest --chain calibnet
</code></pre>
<p>In another shell, you can invoke commands on the running node using
<code>forest-cli</code>. For example, to check the synchronization status:</p>
<pre><code class="language-shell">forest-cli sync status
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli"><a class="header" href="#cli">CLI</a></h1>
<p>The Forest CLI allows for operations to interact with a Filecoin node and the
blockchain.</p>
<h2 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h2>
<p>For nodes not running on a non-default port, or when interacting with a node
remotely, you will need to provide the multiaddress information for the node.
You will need to either set the environment variable <code>FULLNODE_API_INFO</code>, or
prepend it to the command, like so:</p>
<p><code>FULLNODE_API_INFO="..." forest-wallet new -s bls</code></p>
<p>On Linux, you can set the environment variable with the following syntax</p>
<p><code>export FULLNODE_API_INFO="..."</code></p>
<p>Setting your API info this way will limit the value to your current session.
Look online for ways to persist this variable if desired.</p>
<p>The syntax for the <code>FULLNODE_API_INFO</code> variable is as follows:</p>
<p><code>&lt;admin_token&gt;:/ip4/&lt;ip of host&gt;/tcp/&lt;port&gt;/http</code></p>
<p>This will use IPv4, TCP, and HTTP when communicating with the RPC API. The admin
token can be found when starting the Forest daemon. This will be needed to
create tokens with certain permissions such as read, write, sign, or admin.</p>
<h2 id="token-flag"><a class="header" href="#token-flag">Token flag</a></h2>
<p>For nodes running on default port and when you are interacting locally, the
admin token can also be set using <code>--token</code> flag:</p>
<pre><code>forest-cli --token eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJBbGxvdyI6WyJyZWFkIiwid3JpdGUiLCJzaWduIiwiYWRtaW4iXSwiZXhwIjoxNjczMjEwMTkzfQ.xxhmqtG9O3XNTIrOEB2_TWnVkq0JkqzRdw63BdosV0c &lt;subcommand&gt;
</code></pre>
<h2 id="chain-sync"><a class="header" href="#chain-sync">Chain-Sync</a></h2>
<p>The chain-sync CLI can mark blocks to never be synced, provide information about
the state of the syncing process, and check blocks that will never be synced
(and for what reason).</p>
<p>Wait Wait for the sync process to be complete Usage: <code>forest-cli sync wait</code>
Permissions: Read</p>
<p>Status Check the current state of the syncing process, displaying some
information Usage: <code>forest-cli sync status</code> Permissions: Read</p>
<p>Check Bad Check if a block has been marked by, identifying the block by CID
Usage: <code>forest-cli sync check-bad -c &lt;block cid&gt;</code> Permissions: Read</p>
<p>Mark Bad Mark a block as bad, the syncer will never sync this block Usage:
<code>forest-cli sync mark-bad -c &lt;block cid&gt;</code> Permissions: Admin</p>
<h2 id="message-pool"><a class="header" href="#message-pool">Message Pool</a></h2>
<p>The Message Pool (mpool) is the component of forest that handles pending
messages that have reached the node for inclusion in the chain.</p>
<h3 id="display-the-list-of-all-pending-messages"><a class="header" href="#display-the-list-of-all-pending-messages">Display the list of all pending messages</a></h3>
<p>Usage: <code>forest-cli mpool pending</code></p>
<p>Example:</p>
<pre><code>{
  "Message": {
    "Version": 0,
    "To": "t01491",
    "From": "t3sg27lp6xgz3fb7db7t4x4lhmsf3dgu73mj5sodkshh64ftr6dzkrfxrowroon2cr2f3vkumsi4schkpfyvea",
    "Nonce": 14704,
    "Value": "0",
    "GasLimit": 31073678,
    "GasFeeCap": "100507",
    "GasPremium": "99453",
    "Method": 6,
    "Params": "iggZG3DYKlgpAAGC4gOB6AIgRRHJtEnHDx51h/M46ebVUjTD1kowbg+8uWOSrQnQYWwaAAaPXIAaAB45DvQAAAA=",
    "CID": {
      "/": "bafy2bzaceacz2f5k5pcjhzvodhpgin2phycgk2magezaxxp7wcqrjvobbtj5w"
    }
  },
  "Signature": {
    "Type": 2,
    "Data": "hcBY3OATkjMBRly96aViP2CR0R68dqnmlB1k6g2C2EXfe7+AsCN7bF4+M5bA6SecCsP2Fx+NwYkpGBi1CFGon5U9bqilMIiXxuK0mIrNO0d6UocCBGi/IVZwW2K4hT9N"
  },
  "CID": {
    "/": "bafy2bzaceacz2f5k5pcjhzvodhpgin2phycgk2magezaxxp7wcqrjvobbtj5w"
  }
}
</code></pre>
<h3 id="display-the-cids-of-pending-messages"><a class="header" href="#display-the-cids-of-pending-messages">Display the CIDs of pending messages</a></h3>
<p>Usage: <code>forest-cli mpool pending --cids</code></p>
<h3 id="display-the-locally-published-messages-only"><a class="header" href="#display-the-locally-published-messages-only">Display the locally published messages only</a></h3>
<p>Usage: <code>forest-cli mpool pending --local</code></p>
<h3 id="display-the-list-of-all-pending-messages-originating-from-a-given-address"><a class="header" href="#display-the-list-of-all-pending-messages-originating-from-a-given-address">Display the list of all pending messages originating from a given address</a></h3>
<p>Usage: <code>forest-cli mpool pending --from &lt;address&gt;</code></p>
<h3 id="display-the-list-of-all-pending-messages-going-to-a-given-address"><a class="header" href="#display-the-list-of-all-pending-messages-going-to-a-given-address">Display the list of all pending messages going to a given address</a></h3>
<p>Usage: <code>forest-cli mpool pending --to &lt;address&gt;</code></p>
<p>You can retrieve statistics about the current messages in the pool.</p>
<h3 id="display-statistics-of-all-pending-messages"><a class="header" href="#display-statistics-of-all-pending-messages">Display statistics of all pending messages</a></h3>
<p>Usage: <code>forest-cli mpool stat</code></p>
<p>Example:</p>
<pre><code>t3ub2uupkvfwp7zckda2songtluquirgxnooocjfifq6qesxre4igoc3u62njgvmmgnyccmowshbmrolkuni7a: Nonce past: 3, cur: 0, future: 1; FeeCap cur: 0, min-60: 0, gasLimit: 186447391
t3wikyuoalsqxathxey5jcsiowhbmy5o2ip6l4lvpna2rjxjd7micrgmlppjmwwcsnll7xgqzhlqqs6j4xk3oa: Nonce past: 1, cur: 0, future: 0; FeeCap cur: 0, min-60: 0, gasLimit: 66357410
t3wt6c4wla5egncjsgq67lsu4wzu4xtnbeskgupty7udysbiqkr4sw6inqli2nazks2ypwwnmlahtkzd4ghjja: Nonce past: 1, cur: 0, future: 0; FeeCap cur: 0, min-60: 0, gasLimit: 44752713
-----
total: Nonce past: 5, cur: 0, future: 1; FeeCap cur: 0, min-60: 0, gasLimit: 297557514
</code></pre>
<p>The <code>Nonce past</code>, <code>cur</code> (current) and <code>future</code> metrics indicate for each sending
account actor (the first address) how its message nonces are comparing
relatively to its own nonce.</p>
<p>A positive <code>past</code> number indicates messages that have been mined but that are
still present in the message pool and/or messages that could not get included in
a block. A positive <code>cur</code> number indicates all messages that are waiting to be
included in a block. A high number here could mean that the network is enduring
some congestion (if those messages are yours, you need to pay attention to the
different fees you are using and adjust them). A positive <code>future</code> number means
either that your forest node is not fully synced yet or if you are in sync that
some messages are using a too small nonce.</p>
<p>The <code>FeeCap cur</code> and <code>min-60</code> indicate how many messages from the sending
account actor have their basefee below to the current tipset basefee and the
minimum basefee found in the last 60 tipsets, respectively (use
<code>--basefee-lookback</code> flag to change the number of lookback tipsets).</p>
<p>The <code>gasLimit</code> value indicates the sum of <code>gasLimit</code> of all messages from each
sending actor.</p>
<p>The final <code>total</code> line is the accumulated sum of each metric for all messages.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wallet-handling"><a class="header" href="#wallet-handling">Wallet handling</a></h1>
<p>There are two wallets for Forest: One is accessible by the Forest node, and one
is only accessible by you. It is recommended that you only use the local wallet
for security reasons. The wallet in the Forest node exists for backward
compatibility with Lotus.</p>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p>To query an account's balance or transfer funds, you need access to a running
Filecoin node. You can run such a node yourself or use a publicly available
node. As a rule of thumb, only send real money through a node that you trust.
The rest of this document will assume you're using play money on calibnet.</p>
<p>Glif.io runs a public Filecoin node at that we can use by setting
<code>FULLNODE_API_INFO</code>:</p>
<pre><code class="language-bash">export FULLNODE_API_INFO=/dns/api.calibration.node.glif.io/tcp/443/https
</code></pre>
<h2 id="creating-an-account"><a class="header" href="#creating-an-account">Creating an account</a></h2>
<p>Initially, our wallet contains no addresses:</p>
<pre><code>$ forest-wallet list
Address                                   Default Balance
</code></pre>
<p>Let's create a new address and inspects its balance:</p>
<pre><code>$ forest-wallet new
t15ydyu3d65gznpp2qxwpkjsgz4waubeunn6upvla
$ forest-wallet list
Address                                   Default Balance
t15ydyu3d65gznpp2qxwpkjsgz4waubeunn6upvla  X        0 FIL
</code></pre>
<p>The generated address will be unique and it will have a balance of <code>0 FIL</code>.
Since this is a testnet account, we can add FIL to it from the
<a href="https://faucet.calibnet.chainsafe-fil.io/funds.html">faucet</a>/<a href="https://faucet.triangleplatform.com/filecoin/calibration">alternate faucet</a>.</p>
<p>After requesting the funds and waiting roughly a minute, we can see the funds
arrive in our wallet:</p>
<pre><code>$ forest-wallet list
Address                                   Default Balance
t15ydyu3d65gznpp2qxwpkjsgz4waubeunn6upvla  X        100 FIL
</code></pre>
<h2 id="sending-filecoin-tokens-from-your-wallet"><a class="header" href="#sending-filecoin-tokens-from-your-wallet">Sending Filecoin tokens from your wallet</a></h2>
<p>Let's create a new, empty account:</p>
<pre><code>$ forest-wallet new
t14tgmcxrcohfstxuxfbfk2vrjr3tqmefzlajp52y
$ forest-wallet list
Address                                   Default Balance
t14tgmcxrcohfstxuxfbfk2vrjr3tqmefzlajp52y           0 FIL
t15ydyu3d65gznpp2qxwpkjsgz4waubeunn6upvla  X        100 FIL
</code></pre>
<p>We can transfer FIL to this new account from our default account:</p>
<pre><code>$ forest-wallet send t14tgmcxrcohfstxuxfbfk2vrjr3tqmefzlajp52y "1.2 FIL"
bafy2bzaceasy7bzgjwnl4mbjp3tfxdeq4mvdvfne7fj773w7x4d6ah7cdabkc
</code></pre>
<p>It takes a minute or so for the transaction to be included in the Filecoin
blockchain. Once the transaction has gone through, we can inspect our balances:</p>
<pre><code>$ forest-wallet list
Address                                   Default Balance
t14tgmcxrcohfstxuxfbfk2vrjr3tqmefzlajp52y           1200 milliFIL
t15ydyu3d65gznpp2qxwpkjsgz4waubeunn6upvla  X        ~98800 milliFIL
</code></pre>
<p>The gas cost of the transaction is automatically paid from the sending account.</p>
<h2 id="cli-1"><a class="header" href="#cli-1">CLI</a></h2>
<p>The forest-wallet executable offers several subcommand and options:</p>
<pre><code>USAGE:
  forest-wallet [OPTIONS] &lt;COMMAND&gt;

SUBCOMMANDS:
  new               Create a new wallet
  balance           Get account balance
  default           Get the default address of the wallet
  export            Export the wallet's keys
  has               Check if the wallet has a key
  import            Import keys from existing wallet
  list              List addresses of the wallet
  set-default       Set the default wallet address
  sign              Sign a message
  validate-address  Validates whether a given string can be decoded
                    as a well-formed address
  verify            Verify the signature of a message. Returns true
                    if the signature matches the message and address
  delete            Deletes the wallet associated with the given address
  send              Send funds between accounts
  help              Print this message or the help of the given subcommand(s)

OPTIONS:
      --token &lt;TOKEN&gt;  Admin token to interact with the node
      --remote-wallet  Use remote wallet associated with the Filecoin node
      --encrypt        Encrypt local wallet
  -h, --help           Print help
  -V, --version        Print version
</code></pre>
<h2 id="lotus-compatiblity"><a class="header" href="#lotus-compatiblity">Lotus compatiblity</a></h2>
<p>If you want to use the builtin wallet in a Lotus or Forest node, you can use the
<code>forest-wallet</code> executable with the <code>--remote-wallet</code> option. The subcommands
remain the same but require write access to the remote Filecoin node.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h1>
<p>The <code>forest</code> process has a set of configurable values which determine the
behavior of the node. All values can be set through process flags or through a
configuration file. If a configuration is provided through the flag and the
configuration file, the flag value will be given preference.</p>
<h2 id="flags"><a class="header" href="#flags">Flags</a></h2>
<p>When starting <code>forest</code> you can configure the behavior of the process through the
use of the following flags:</p>
<div class="table-wrapper"><table><thead><tr><th>Flag</th><th>Value</th><th>Description</th></tr></thead><tbody>
<tr><td>--config</td><td>OS File Path</td><td>Path to TOML file containing configuration</td></tr>
<tr><td>--genesis</td><td>OS File Path</td><td>CAR file with genesis state</td></tr>
<tr><td>--rpc</td><td>Boolean</td><td>Toggles the RPC API on</td></tr>
<tr><td>--port</td><td>Integer</td><td>Port for JSON-RPC communication</td></tr>
<tr><td>--token</td><td>String</td><td>Client JWT token to use for JSON-RPC authentication</td></tr>
<tr><td>--metrics-port</td><td>Integer</td><td>Port used for metrics collection server</td></tr>
<tr><td>--kademlia</td><td>Boolean</td><td>Determines whether Kademilia is allowed</td></tr>
<tr><td>--mdns</td><td>Boolean</td><td>Determines whether MDNS is allowed</td></tr>
<tr><td>--import-snapshot</td><td>OS File Path</td><td>Path to snapshot CAR file</td></tr>
<tr><td>--import-mode</td><td>String</td><td>Snapshot import mode: Copy, Move, Symlink</td></tr>
<tr><td>--skip-load</td><td>Boolean</td><td>Skips loading CAR File and uses header to index chain</td></tr>
<tr><td>--req-window</td><td>Integer</td><td>Sets the number of tipsets requested over chain exchange</td></tr>
<tr><td>--tipset-sample-size</td><td>Integer</td><td>Number of tipsets to include in the sample which determines the network head during synchronization</td></tr>
<tr><td>--target-peer-count</td><td>Integer</td><td>Amount of peers the node should maintain a connection with</td></tr>
<tr><td>--encrypt-keystore</td><td>Boolean</td><td>Controls whether the keystore is encrypted</td></tr>
</tbody></table>
</div>
<h2 id="configuration-file"><a class="header" href="#configuration-file">Configuration File</a></h2>
<p>Alternatively, when starting <code>forest</code> you can define a TOML configuration file
and provide it to the process with the <code>--config</code> flag or through the
<code>FOREST_CONFIG_PATH</code> environment variable.</p>
<p>The following is an sample configuration file:</p>
<pre><code class="language-toml">genesis = "/path/to/genesis/file"
rpc = true
port = 1234
token = "0394j3094jg0394jg34g"
metrics-port = 2345
kademlia = true
mdns = true
import-snapshot = /path/to/snapshot/file
import-chain = /path/to/chain/file
skip-load = false
req-window = 100
tipset-sample-size = 10
target-peer-count = 100
encrypt-keystore = false
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment variables</a></h1>
<p>Besides CLI options and the configuration values in the configuration file,
there are some environment variables that control the behaviour of a <code>forest</code>
process.</p>
<div class="table-wrapper"><table><thead><tr><th>Environment variable</th><th>Value</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td>FOREST_KEYSTORE_PHRASE</td><td>any text</td><td>empty</td><td>The passphrase for the encrypted keystore</td></tr>
<tr><td>FOREST_CAR_LOADER_FILE_IO</td><td>1 or true</td><td>false</td><td>Load CAR files with <code>RandomAccessFile</code> instead of <code>Mmap</code></td></tr>
<tr><td>FOREST_DB_DEV_MODE</td><td><a href="environment_variables.html#-forest_db_dev_mode">see here</a></td><td>current</td><td>The database to use in development mode</td></tr>
<tr><td>FOREST_ACTOR_BUNDLE_PATH</td><td>file path</td><td>empty</td><td>Path to the local actor bundle, download from remote servers when not set</td></tr>
<tr><td>FIL_PROOFS_PARAMETER_CACHE</td><td>dir path</td><td>empty</td><td>Path to folder that caches fil proof parameter files</td></tr>
<tr><td>FOREST_PROOFS_ONLY_IPFS_GATEWAY</td><td>1 or true</td><td>false</td><td>Use only IPFS gateway for proofs parameters download</td></tr>
<tr><td>FOREST_FORCE_TRUST_PARAMS</td><td>1 or true</td><td>false</td><td>Trust the parameters downloaded from the Cloudflare/IPFS</td></tr>
<tr><td>IPFS_GATEWAY</td><td>URL</td><td>https://proofs.filecoin.io/ipfs/</td><td>The IPFS gateway to use for downloading proofs parameters</td></tr>
<tr><td>FOREST_RPC_DEFAULT_TIMEOUT</td><td>Duration (in seconds)</td><td>60</td><td>The default timeout for RPC calls</td></tr>
<tr><td>FOREST_MAX_CONCURRENT_REQUEST_RESPONSE_STREAMS_PER_PEER</td><td>positive integer</td><td>10</td><td>the maximum concurrent streams per peer for request-response-based p2p protocols</td></tr>
<tr><td>FOREST_BLOCK_DELAY_SECS</td><td>positive integer</td><td>Depends on the network</td><td>Duration of each tipset epoch</td></tr>
<tr><td>FOREST_PROPAGATION_DELAY_SECS</td><td>positive integer</td><td>Depends on the network</td><td>How long to wait for a block to propagate through the network</td></tr>
</tbody></table>
</div>
<h3 id="forest_db_dev_mode"><a class="header" href="#forest_db_dev_mode">FOREST_DB_DEV_MODE</a></h3>
<p>By default, Forest will create a database of its current version or try to
migrate to it. This can be overridden with the <code>FOREST_DB_DEV_MODE</code>
environmental variable.</p>
<div class="table-wrapper"><table><thead><tr><th>Value</th><th>Description</th></tr></thead><tbody>
<tr><td><code>current</code> or (unset)</td><td>Forest will either create a new database with the current version or attempt a migration if possible. On failure, it will create a new database.</td></tr>
<tr><td><code>latest</code></td><td>Forest will use the latest versioned database. No migration will be performed.</td></tr>
<tr><td>other values (e.g., <code>cthulhu</code>)</td><td>Forest will use the provided database (if it exists, otherwise it will create one under this name)</td></tr>
</tbody></table>
</div>
<p>The databases can be found, by default, under <code>&lt;DATA_DIR&gt;/&lt;chain&gt;/</code>, e.g.,
<code>$HOME/.local/share/forest/calibnet</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forest-in-docker"><a class="header" href="#forest-in-docker">Forest in Docker🌲❤️🐋</a></h1>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li>Docker engine installed and running. Forest containers are confirmed to run on
the following engines:
<ul>
<li>Docker Engine (Community) on Linux,</li>
<li>Docker for macOS</li>
<li>Podman on WSL</li>
</ul>
</li>
</ul>
<p>Native images are available for the following platforms:</p>
<ul>
<li><code>linux/arm64</code></li>
<li><code>linux/amd64</code></li>
</ul>
<p>The images will work out-of-the box on both Intel processors and macOS with
M1/M2.</p>
<h2 id="tags"><a class="header" href="#tags">Tags</a></h2>
<p>For the list of all available tags please refer to the
<a href="https://github.com/ChainSafe/forest/pkgs/container/forest">Forest packages</a>.</p>
<p>Currently, the following tags are produced:</p>
<ul>
<li><code>latest</code> - latest stable release,</li>
<li><code>edge</code> - latest development build of the <code>main</code> branch,</li>
<li><code>date-digest</code> e.g., <code>2023-02-17-5f27a62</code> - all builds that landed on the
<code>main</code> branch,</li>
<li>release tags, available from <code>v.0.7.0</code> onwards.</li>
</ul>
<h2 id="security-recommendations"><a class="header" href="#security-recommendations">Security recommendations</a></h2>
<ul>
<li>We strongly recommend running the docker daemon in rootless mode
(<a href="https://docs.docker.com/engine/security/rootless/">installation instructions</a>),
or running the daemon-less docker alternative <code>podman</code>
(<a href="https://podman.io/getting-started/installation">installation instructions</a>)
with non-root user and put <code>alias docker = podman</code> (or manually replace the
<code>docker</code> commands with <code>podman</code> in below instructions)</li>
</ul>
<h2 id="performance-recommendations"><a class="header" href="#performance-recommendations">Performance recommendations</a></h2>
<ul>
<li>We recommend lowering the swappiness kernel parameter on linux to 1-10 for
long running forest node by doing <code>sudo sysctl -w vm.swappiness=[n]</code>.</li>
</ul>
<p>References: <a href="https://en.wikipedia.org/wiki/Memory_paging#Swappiness">1</a>
<a href="https://linuxhint.com/understanding_vm_swappiness/">2</a></p>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<h3 id="list-available-flags-andor-commands"><a class="header" href="#list-available-flags-andor-commands">List available flags and/or commands</a></h3>
<pre><code class="language-shell"># daemon
❯ docker run --init -it --rm ghcr.io/chainsafe/forest:latest --help
# cli
❯ docker run --init -it --rm --entrypoint forest-cli ghcr.io/chainsafe/forest:latest --help
</code></pre>
<p>Also see the <a href="./cli.html">CLI documentation</a> for more details about commands and
their usage.</p>
<h3 id="create-a-forest-node-running-calibration-network-then-list-all-connected-peers"><a class="header" href="#create-a-forest-node-running-calibration-network-then-list-all-connected-peers">Create a Forest node running calibration network. Then list all connected peers.</a></h3>
<pre><code class="language-shell">❯ docker run --init -it --rm --name forest ghcr.io/chainsafe/forest:latest --chain calibnet --auto-download-snapshot
</code></pre>
<p>then in another terminal (sample output)</p>
<pre><code class="language-shell">❯ docker exec -it forest forest-cli net peers
12D3KooWAh4qiT3ZRZgctVJ8AWwRva9AncjMRVBSkFwNjTx3EpEr, [/ip4/10.0.2.215/tcp/1347, /ip4/52.12.185.166/tcp/1347]
12D3KooWMY4VdMsdbFwkHv9HxX2jZsUdCcWFX5F5VGzBPZkdxyVr, [/ip4/162.219.87.149/tcp/30141, /ip4/162.219.87.149/tcp/30141/p2p/12D3KooWMY4VdMsdbFwkHv9HxX2jZsUdCcWFX5F5VGzBPZkdxyVr]
12D3KooWFWUqE9jgXvcKHWieYs9nhyp6NF4ftwLGAHm4sCv73jjK, [/dns4/bootstrap-3.calibration.fildev.network/tcp/1347]
</code></pre>
<h3 id="use-a-shared-volume-to-utilise-across-different-forest-images"><a class="header" href="#use-a-shared-volume-to-utilise-across-different-forest-images">Use a shared volume to utilise across different Forest images</a></h3>
<p>Create the volume</p>
<pre><code class="language-shell">docker volume create forest-data
</code></pre>
<p>Now, whenever you create a new Forest container, attach the volume to where the
data is stored <code>/home/forest/.local/share/forest</code>.</p>
<pre><code class="language-shell">❯ docker run --init -it --rm \
             --ulimit nofile=8192 \
             --volume forest-data:/home/forest/.local/share/forest \
             --name forest ghcr.io/chainsafe/forest:latest --chain calibnet
                                                           --auto-download-snapshot
</code></pre>
<h3 id="export-the-calibnet-snapshot-to-the-host-machine"><a class="header" href="#export-the-calibnet-snapshot-to-the-host-machine">Export the calibnet snapshot to the host machine</a></h3>
<p>Assuming you have <code>forest</code> container already running, run:</p>
<pre><code class="language-shell">❯ docker exec -it forest forest-cli --chain calibnet snapshot export
Export completed. Snapshot located at forest_snapshot_calibnet_2023-02-17_height_308891.car
</code></pre>
<p>Copy the snapshot to the host</p>
<pre><code class="language-shell">❯ docker cp forest:/home/forest/forest_snapshot_calibnet_2023-02-17_height_308891.car .
</code></pre>
<h3 id="create-and-fund-a-wallet-then-send-some-fil-on-calibration-network"><a class="header" href="#create-and-fund-a-wallet-then-send-some-fil-on-calibration-network">Create and fund a wallet, then send some FIL on calibration network</a></h3>
<p>Assuming you have <code>forest</code> container already running, you need to find the JWT
token in the logs.</p>
<pre><code class="language-shell">❯ docker logs forest | grep "Admin token"
</code></pre>
<p>export it to an environmental variable for convenience (sample, use the token
you obtained in the previous step)</p>
<pre><code class="language-shell">export JWT_TOKEN=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJBbGxvdyI6WyJyZWFkIiwid3JpdGUiLCJzaWduIiwiYWRtaW4iXSwiZXhwIjoxNjgxODIxMTc4fQ.3toXEeiGcHT01pUjQeqMyW2kZmQpqpE4Gi4vOHjX4rE
</code></pre>
<p>Create the wallet</p>
<pre><code class="language-shell">❯ docker exec -it forest forest-wallet --token $JWT_TOKEN new
t1uvqpa2jgic7fhhko3w4wf3kxj36qslvqrk2ln5i
</code></pre>
<p>You can fund your wallet using this
<a href="https://faucet.calibration.fildev.network/funds.html">faucet</a>. If this faucet
is unavailable or does not work, there is an
<a href="https://faucet.triangleplatform.com/filecoin/calibration">alternative faucet</a>.
You can verify your wallet was funded after a few minutes in
<a href="https://calibration.filscan.io/">Filscan</a> by pasting the Message ID obtained
from the faucet. Example from
<a href="https://calibration.filscan.io/tipset/message-detail?cid=bafy2bzacebdverplts5qs3lwzsenzlh4rdsmvc42r6yg6suu4comr7gkbe76a">this wallet</a>.</p>
<p>Verify that your account has 100 FIL . The result is in <code>attoFIL</code>.</p>
<pre><code class="language-shell">❯ docker exec -it forest forest-wallet --token $JWT_TOKEN balance t1uvqpa2jgic7fhhko3w4wf3kxj36qslvqrk2ln5i
100000000000000000000
</code></pre>
<p>Create another wallet</p>
<pre><code class="language-shell">❯ docker exec -it forest forest-wallet --token $JWT_TOKEN new
t1wa7lgs7b3p5a26abkgpxwjpw67tx4fbsryg6tca
</code></pre>
<p>Send 10 FIL from the original wallet to the new one (default unit for the amount
in send command is FIL).</p>
<pre><code class="language-shell">❯ docker exec -it forest forest-cli --chain calibnet --token $JWT_TOKEN send --from t1uvqpa2jgic7fhhko3w4wf3kxj36qslvqrk2ln5i t1wa7lgs7b3p5a26abkgpxwjpw67tx4fbsryg6tca 10
</code></pre>
<p>Verify the balance of the new address.
<a href="https://calibration.filscan.io/tipset/message-detail?cid=bafy2bzacebymw25tedmec4xnwmf7fcrt64qvfbbuacbx6lnhyrcbfv3rgkn2a">Sample transaction</a>
for this wallet.</p>
<pre><code class="language-shell">❯ docker exec -it forest forest-wallet --token $JWT_TOKEN balance t1wa7lgs7b3p5a26abkgpxwjpw67tx4fbsryg6tca
10000000000000000000
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="healthcheck-"><a class="header" href="#healthcheck-">Healthcheck 🩺</a></h1>
<p>It is helpful for monitoring and alerting systems to check if the node is up and
running out of the box. Forest ships with a set of healthcheck endpoints that
can be used to monitor the node status and perform actions based on the results.</p>
<h2 id="endpoints"><a class="header" href="#endpoints">Endpoints</a></h2>
<p>All healthcheck endpoints operate on port <code>2346</code> by default. This behaviour can
be changed via the <code>--healthcheck-address</code> flag. All endpoints expose a
<code>verbose</code> optional query parameter that can be used to get more detailed
information about the node's health status.</p>
<p>Endpoints return a <code>200 OK</code> status code if the node is healthy and a
<code>503 Service Unavailable</code> status code if the node is not healthy.</p>
<h3 id="livez"><a class="header" href="#livez"><code>/livez</code></a></h3>
<p>Liveness probes determine whether or not an application running in a container
is in a healthy state. The idea behind a liveness probe is that it fails for
prolonged period of time, then the application should be restarted. In our case,
we require:</p>
<ul>
<li>The node is not in an error state (i.e., boot-looping)</li>
<li>At least 1 peer is connected (without peers, the node is isolated and cannot
sync)</li>
</ul>
<p>If any of these conditions are not met, the node is <strong>not</strong> healthy. If this
happens for a prolonged period of time, the application should be restarted.</p>
<p>Sample <em>lively</em> response:</p>
<pre><code>❯ curl "http://127.0.0.1:2346/livez?verbose"
[+] sync ok
[+] peers connected⏎
</code></pre>
<p>Sample <em>not lively</em> response:</p>
<pre><code>❯ curl "http://127.0.0.1:2346/livez?verbose"
[+] sync ok
[!] no peers connected
</code></pre>
<h3 id="readyz"><a class="header" href="#readyz"><code>/readyz</code></a></h3>
<p>Readiness probes determine whether or not a container is ready to serve
requests. The goal is to determine if the application is fully prepared to
accept traffic. In our case, we require:</p>
<ul>
<li>The node is in sync with the network</li>
<li>The current epoch of the node is not too far behind the network</li>
<li>The RPC server is running</li>
<li>The Ethereum mapping is up to date</li>
</ul>
<p>If any of these conditions are not met, the node is <strong>not</strong> ready to serve
requests.</p>
<p>Sample <em>ready</em> response:</p>
<pre><code>❯ curl "http://127.0.0.1:2346/readyz?verbose"
[+] sync complete
[+] epoch up to date
[+] rpc server running
[+] eth mapping up to date⏎
</code></pre>
<p>Sample <em>not ready</em> response:</p>
<pre><code>❯ curl "http://127.0.0.1:2346/readyz?verbose"
[!] sync incomplete
[!] epoch outdated
[+] rpc server running
[!] no eth mapping⏎
</code></pre>
<h3 id="healthz"><a class="header" href="#healthz"><code>/healthz</code></a></h3>
<p>This endpoint is a combination of the <code>/livez</code> and <code>/readyz</code> endpoints, except
that the node doesn't have to be fully synced. Deprecated in the Kubernetes
world, but still used in some setups.</p>
<p>Sample <em>healthy</em> response:</p>
<pre><code>❯ curl "http://127.0.0.1:2346/healthz?verbose"
[+] sync complete
[+] epoch up to date
[+] rpc server running
[+] sync ok
[+] peers connected⏎
</code></pre>
<p>Sample <em>unhealthy</em> response:</p>
<pre><code>❯ curl "http://127.0.0.1:2346/healthz?verbose"
[!] sync incomplete
[!] epoch outdated
[+] rpc server running
[+] sync ok
[!] no peers connected⏎
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="snapshot-exporting-"><a class="header" href="#snapshot-exporting-">Snapshot exporting 📸</a></h1>
<h2 id="hardware-requirements"><a class="header" href="#hardware-requirements">Hardware requirements</a></h2>
<p>To export a mainnet snapshot, you need a setup with at least 10 GB of RAM. On a
machine with rapid NVMe SSD (around 7000MB/s), the export should take around 30
minutes.</p>
<p>The requirements for calibnet snapshots are lower, but it is still recommended
to have at least 4 GB of RAM. The export should take less than a minute.</p>
<h2 id="running-the-node"><a class="header" href="#running-the-node">Running the node</a></h2>
<p>You need to have a running node to be able to export a snapshot. If you don't
have one, you can follow the <a href="./basic_usage.html">usage guide</a>.</p>
<p>Wait until the node is fully synced. You can use the command:</p>
<pre><code class="language-shell">forest-cli sync wait
</code></pre>
<h2 id="exporting-the-snapshot"><a class="header" href="#exporting-the-snapshot">Exporting the snapshot</a></h2>
<p>Usage of the <code> snapshot export</code> command:</p>
<pre><code class="language-shell">Usage: forest-cli snapshot export [OPTIONS]

Options:
  -o &lt;OUTPUT_PATH&gt;      Snapshot output filename or directory. Defaults to
                        `./forest_snapshot_{chain}_{year}-{month}-{day}_height_{epoch}.car.zst`. [default: .]
      --skip-checksum   Skip creating the checksum file
      --dry-run         Don't write the archive
  -h, --help            Print help
</code></pre>
<p>The snapshot will be exported with 2000 recent stateroots.</p>
<p>To export the snapshot with the defaults, run:</p>
<pre><code class="language-shell">forest-cli snapshot export
</code></pre>
<p>it will write the snapshot to the current directory. The snapshot will be
compressed.</p>
<p>For mainnet, you should expect a file of over 50 GB. For calibnet, you should
expect a file of around 1-2 GB.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="json-rpc-api"><a class="header" href="#json-rpc-api">JSON-RPC API</a></h1>
<div class="warning">
<p>This API is still a WIP, with more methods being added continuously.</p>
<p>Need a specific method? Let us know on
<a href="https://github.com/ChainSafe/forest/issues">Github</a> or Filecoin Slack
(<code>#fil-forest-help</code>) 🙏</p>
</div>
<h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<p>The RPC interface is the primary mechanism for interacting with Forest. The
implementation is still a WIP, with support for more methods being added
continuously.</p>
<p>As there is presently no cross-client specification, the Lotus
<a href="https://github.com/filecoin-project/lotus/blob/master/documentation/en/api-v0-methods.md">V0</a>
and
<a href="https://github.com/filecoin-project/lotus/blob/master/documentation/en/api-v1-unstable-methods.md">V1</a>
APIs are the reference for Forest's implementation.</p>
<h1 id="supported-methods"><a class="header" href="#supported-methods">Supported Methods</a></h1>
<p>We currently track all methods and their implementation state
<a href="https://github.com/orgs/ChainSafe/projects/29">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forest-backups"><a class="header" href="#forest-backups">Forest Backups</a></h1>
<blockquote>
<p>"<em>The condition of any backup is unknown until a restore is attempted.</em>"
Everyone who deals with backups.</p>
</blockquote>
<h2 id="manual-backups"><a class="header" href="#manual-backups">Manual backups</a></h2>
<p>The manual way requires knowledge of Forest internals and how it structures its
data directory (which is not guaranteed to stay the same). Thus, it is
recommended to use alternatives.</p>
<h2 id="backups-with-the-forest-tool"><a class="header" href="#backups-with-the-forest-tool">Backups with the <code>forest-tool</code></a></h2>
<p>Forest comes with a <code>forest-tool</code> binary, which handles creating and recovering
backups.</p>
<h3 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic usage</a></h3>
<p>:warning: <strong>The Forest node should be offline during the backup process,
especially when backing up the blockstore.</strong></p>
<p><code>forest-tool backup create</code> will create a backup file in the current working
directory. It will contain the p2p keypair used to derive the <code>PeerId</code> and the
keystore. If storing anywhere, make sure to encrypt it.</p>
<pre><code>❯ forest-tool backup create
Adding /home/rumcajs/.local/share/forest/libp2p/keypair to backup
Adding /home/rumcajs/.local/share/forest/keystore.json to backup
Backup complete: forest-backup-2024-02-22_17-18-43.tar
</code></pre>
<p>Afterwards, you can use <code>forest-tool backup restore &lt;backup-file&gt;</code> to restore
those files. Note that this assumes that Forest is using the default
configuration - if it's not the case, provide the configuration TOML file via
the <code>--daemon-config</code> parameter.</p>
<pre><code>❯ forest-tool backup restore forest-backup-2024-02-22_17-18-43.tar
Restoring /home/rumcajs/.local/share/forest/libp2p/keypair
Restoring /home/rumcajs/.local/share/forest/keystore.json
Restore complete
</code></pre>
<p>There are other flags to the backup tool, most notably <code>--all</code>, that will back
up the entire Forest data directory. Note that this includes the whole
blockstore, which, for mainnet, can reach hundreds of gigabytes. It is not
recommended outside development.</p>
<h3 id="backup"><a class="header" href="#backup"><code>backup</code></a></h3>
<pre><code>Create and restore backups

Usage: forest-tool backup &lt;COMMAND&gt;

Commands:
  create   Create a backup of the node. By default, only the p2p keypair and keystore are backed up. The node must be offline
  restore  Restore a backup of the node from a file. The node must be offline
  help     Print this message or the help of the given subcommand(s)
</code></pre>
<h3 id="backup-create"><a class="header" href="#backup-create"><code>backup create</code></a></h3>
<pre><code>Create a backup of the node. By default, only the p2p keypair and keystore are backed up. The node must be offline

Usage: forest-tool backup create [OPTIONS]

Options:
      --backup-file &lt;BACKUP_FILE&gt;      Path to the output backup file if not using the default
      --all                            Backup everything from the Forest data directory. This will override other options
      --no-keypair                     Disables backing up the keypair
      --no-keystore                    Disables backing up the keystore
      --backup-chain &lt;BACKUP_CHAIN&gt;    Backs up the blockstore for the specified chain. If not provided, it will not be backed up
      --include-proof-params           Include proof parameters in the backup
  -d, --daemon-config &lt;DAEMON_CONFIG&gt;  Optional TOML file containing forest daemon configuration. If not provided, the default configuration will be used
  -h, --help                           Print help
</code></pre>
<h3 id="backup-restore"><a class="header" href="#backup-restore"><code>backup restore</code></a></h3>
<pre><code>Restore a backup of the node from a file. The node must be offline

Usage: forest-tool backup restore [OPTIONS] &lt;BACKUP_FILE&gt;

Arguments:
  &lt;BACKUP_FILE&gt;  Path to the backup file

Options:
  -d, --daemon-config &lt;DAEMON_CONFIG&gt;  Optional TOML file containing forest daemon configuration. If not provided, the default configuration will be used
      --force                          Force restore even if files already exist WARNING: This will overwrite existing files
  -h, --help                           Print help
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="trouble-shooting"><a class="header" href="#trouble-shooting">Trouble Shooting</a></h1>
<h2 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h2>
<h4 id="jemalloc-issues-on-apple-silicon-macs"><a class="header" href="#jemalloc-issues-on-apple-silicon-macs">Jemalloc issues on Apple Silicon macs</a></h4>
<p>Forest is compiled with <code>jemalloc</code> as a default allocator. If you are having
problems running or compiling Forest, use this checklist:</p>
<ol>
<li>Make sure you are using an arm64 version of homebrew; this could be a problem
one inherits when migrating from an Intel Mac to Apple Silicon:
<a href="https://stackoverflow.com/a/68443301">Stackoverflow example</a>.</li>
<li>Make sure your default host is set to <code>aarch64-apple-darwin</code> via
<code>rustup set default-host aarch64-apple-darwin</code>.</li>
<li>This could result in various errors related to the fact that you still have
some of the libraries symlinked to <code>/usr/local/lib</code> from an intel Homebrew
installation. The easiest fix for this is:
<ul>
<li>Remove the libraries in question from <code>/usr/local/lib</code>.</li>
<li>Add <code>export LIBRARY_PATH=/opt/homebrew/lib</code> to your bash profile.</li>
<li>Source the new bash profile.</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="algorand"><a class="header" href="#algorand">Algorand</a></h2>
<p><a href="https://www.algorand.com/">Algorand</a> is a proof-of-stake blockchain
cryptocurrency protocol.</p>
<h2 id="blake2b"><a class="header" href="#blake2b">BLAKE2b</a></h2>
<p>BLAKE2 is a cryptographic hash function based on
<a href="https://en.wikipedia.org/wiki/BLAKE_(hash_function)">BLAKE</a>. The design goal
was to replace the widely used, but broken, MD5 and SHA-1 algorithms in
applications requiring high performance in software.</p>
<h2 id="bls"><a class="header" href="#bls">BLS</a></h2>
<p><a href="https://en.wikipedia.org/wiki/BLS_digital_signature">BLS</a> stands for
Boneh–Lynn–Shacham cryptographic signature scheme, which is a cryptographic
signature scheme which allows a user to verify that a signer is authentic.</p>
<h2 id="cbor"><a class="header" href="#cbor">CBOR</a></h2>
<p><a href="https://cbor.io/">CBOR</a> stands for the Concise Binary Object Representation,
which is a data format whose design goals include the possibility of extremely
small code size, fairly small message size, and extensibility without the need
for version negotiation.</p>
<h2 id="cid"><a class="header" href="#cid">CID</a></h2>
<p><a href="https://spec.filecoin.io/#section-libraries.multiformats.cids">CID</a> is short
for Content Identifier, a self describing content address used throughout the
IPFS ecosystem. CIDs are used in Filecoin to identify files submitted to the
decentralized storage network. For more detailed information, see
<a href="https://github.com/ipld/cid">the github documentation for it</a>.</p>
<h2 id="ipld"><a class="header" href="#ipld">IPLD</a></h2>
<p><a href="https://github.com/ipld">IPLD</a> stands for InterPlanetary Linked Data, which is
a series of standards and formats for describing data in a
content-addressing-emphatic way.</p>
<h2 id="jwt"><a class="header" href="#jwt">JWT</a></h2>
<p><a href="https://en.wikipedia.org/wiki/JSON_Web_Token">JWT</a> stands for JSON Web Token,
which is a proposed Internet standard for creating data with optional signature
and/or optional encryption whose payload holds JSON that asserts some number of
claims. The tokens are signed either using a private secret or a public/private
key.</p>
<h2 id="secp"><a class="header" href="#secp">SECP</a></h2>
<p>types of elliptic curves used for ECDSA see
<a href="https://www.johndcook.com/blog/2018/08/21/a-tale-of-two-elliptic-curves/">here</a></p>
<h2 id="multisig"><a class="header" href="#multisig">multisig</a></h2>
<p>A <a href="https://lotus.filecoin.io/lotus/manage/multisig/">multi-signature</a> (multisig)
wallet refers to a wallet that requires multiple keys to authorize a <code>FIL</code>
transactions.</p>
<h2 id="tipset"><a class="header" href="#tipset">Tipset</a></h2>
<p>Tipset is a structure that contains a non-empty collection of blocks that have
distinct miners and all specify identical epoch, parents, weight, height, state
root, receipt root</p>
<h2 id="tipsetkey"><a class="header" href="#tipsetkey">Tipsetkey</a></h2>
<p>A set of CIDs forming a unique key for a tipset.</p>
<h2 id="mempool"><a class="header" href="#mempool">mempool</a></h2>
<p>mempool stands for the Message Pool, which is the component of forest that
handles pending messages for inclusion in the chain. Messages are added either
directly for locally published messages or through pubsub propagation.</p>
<h2 id="merkle"><a class="header" href="#merkle">Merkle</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a> is a tree in which
every node is labelled with the cryptographic hash of a data block, and every
node that is not a leaf (called a branch, inner node, or inode) is labelled with
the cryptographic hash of the labels of its child nodes. A hash tree allows
efficient and secure verification of the contents of a large data structure.</p>
<h2 id="ipfs"><a class="header" href="#ipfs">IPFS</a></h2>
<p><a href="https://github.com/ipfs/ipfs">IPFS</a> stands for InterPlanetary File System which
is a peer-to-peer hypermedia protocol to make the web faster, safer, and more
open.</p>
<h2 id="proof-of-spacetime-post"><a class="header" href="#proof-of-spacetime-post">Proof of Spacetime (PoSt)</a></h2>
<p>PoSt stands for Proof-of-Spacetime is a procedure by which a storage-miner can
prove to the Filecoin network they have stored and continue to store a unique
copy of some data on behalf of the network for a period of time.</p>
<h2 id="hamt"><a class="header" href="#hamt">HAMT</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Hash_array_mapped_trie">HAMT</a> stands for Hash
array mapped trie, which is an implementation of an associative array that
combines the characteristics of a hash table and an array mapped trie.</p>
<h2 id="vrf"><a class="header" href="#vrf">VRF</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Verifiable_random_function">VRF</a> stands for a
Verifiable Random Function that receives a Secret Key (SK) and a seed and
outputs proof of correctness and output value. VRFs must yield a proof of
correctness and a unique &amp; efficiently verifiable output.</p>
<h2 id="mdns"><a class="header" href="#mdns">MDNS</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Multicast_DNS">MDNS</a> stands for Multicast DNS,
which is a protocol, that resolves hostnames to IP addresses within small
networks that do not include a local name server.</p>
<h2 id="kademlia"><a class="header" href="#kademlia">Kademlia</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Kademlia">Kademlia</a> is a distributed hash table
for decentralized peer-to-peer computer networks.</p>
<h2 id="libp2p"><a class="header" href="#libp2p">LibP2P</a></h2>
<p><a href="https://libp2p.io/">LibP2P</a> is a modular system of protocols, specifications
and libraries that enable the development of peer-to-peer network applications.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bootstrap-node"><a class="header" href="#bootstrap-node">Bootstrap node</a></h1>
<p>⚠️ <strong>The Forest bootstrap node connectivity turned out to be below expectations,
as were the hardware requirements. As such, it's better to hold off hosting
Forest as a bootstrap node until issue
<a href="https://github.com/ChainSafe/forest/issues/4346">#4346</a> is resolved.</strong></p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>A bootstrap node is the first node a new node contacts when it joins the
network. It is responsible for providing the new node with a list of other nodes
in the network, which the new node can then contact to join the network. Every
Forest node has a list of bootstrap nodes that it can contact to join the
network. This list is hardcoded into the node but can be modified by the user
via the configuration file.</p>
<h2 id="forest-as-a-bootstrap-node"><a class="header" href="#forest-as-a-bootstrap-node">Forest as a bootstrap node</a></h2>
<p>Every Forest node can act as a bootstrap node. That said, running a <code>stateless</code>
node as a bootstrap node is recommended to lower the hardware requirements. A
<code>stateless</code> node does not store the network's state or participate in the
consensus process. It only serves as a gateway for new nodes to join the
network.</p>
<p>Stateless node characteristics:</p>
<ul>
<li>it connects to the P2P swarm but does not store the state of the network,</li>
<li>it does not sync the chain,</li>
<li>it does not validate the chain,</li>
<li><code>Hello</code> requests' heaviest tipset is the genesis tipset (unless the node was
initialized with a snapshot),</li>
<li><code>ChainExchange</code> responses are <code>PartialResponses</code>.</li>
</ul>
<h2 id="running-a-forest-node-as-a-bootstrap-node"><a class="header" href="#running-a-forest-node-as-a-bootstrap-node">Running a Forest node as a bootstrap node</a></h2>
<p>To run Forest with the stateless mode enabled, you must set the <code>--stateless</code>
flag when starting the node. For example:</p>
<pre><code class="language-bash"># Mainnet
forest --stateless

# Calibnet
forest --stateless --chain calibnet
</code></pre>
<p>The default peer count is likely too small for a bootstrap node. You can set the
<code>--target-peer-count &lt;number&gt;</code> flag to increase the number of peers. For
example:</p>
<pre><code class="language-bash">forest --stateless --target-peer-count 10000
</code></pre>
<h2 id="hardware-requirements-1"><a class="header" href="#hardware-requirements-1">Hardware requirements</a></h2>
<p>The stateless node has lower hardware requirements than a full node. The exact
requirements depend on the number of allowed peers. For 10'000 peers, 512 MiB of
RAM and 1 vCPU should be sufficient.</p>
<h2 id="converting-lotus-node-into-forest-node-and-back"><a class="header" href="#converting-lotus-node-into-forest-node-and-back">Converting Lotus node into Forest node (and back)</a></h2>
<p>You can use the <code>forest-tool shed</code> commands to convert a Lotus node into a
Forest node without losing the peer identity.</p>
<p>First, the data of both the Lotus and Forest nodes must be backed up. By
default, relevant keys in Lotus are in <code>~/.lotus/keystore</code> and in Forest in
<code>~/.local/share/forest/libp2p/</code>.</p>
<h3 id="lotus-to-forest"><a class="header" href="#lotus-to-forest">Lotus to Forest</a></h3>
<p>You need to convert the Lotus key into a Forest key. In the <code>~/.lotus/keystore</code>
directory, identify the file with the <code>libp2p-host</code> type. For example:</p>
<pre><code class="language-json">{ "Type": "libp2p-host", "PrivateKey": "&lt;KEY&gt;" }
</code></pre>
<p>Write the <code>PrivateKey</code> value to a file, for example <code>lotus_key</code>. Then, run the
following command:</p>
<pre><code class="language-bash">forest-tool shed key-pair-from-private-key $(cat lotus_key) | base64 -d &gt; keypair
</code></pre>
<p>Now you can move the <code>keypair</code> file to the <code>~/.local/share/forest/libp2p/</code>
directory. Done!</p>
<h3 id="forest-to-lotus"><a class="header" href="#forest-to-lotus">Forest to Lotus</a></h3>
<p>First, convert the keypair file used by Forest into a private key used by Lotus:</p>
<pre><code class="language-bash">❯ forest-tool shed private-key-from-key-pair &gt; lotus_key
</code></pre>
<p>Then, copy the content to the relevant file's (one with the type <code>libp2p-host</code>
in <code>~/.lotus/keystore/</code>) <code>PrivateKey</code> value. Done!</p>
<h2 id="additional-resources"><a class="header" href="#additional-resources">Additional resources</a></h2>
<ul>
<li><a href="https://blog.ipfs.tech/2023-rust-libp2p-based-ipfs-bootstrap-node/#ipfs-public-dht-bootstrap-nodes">DHT Bootstrap nodes</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="offline-forest"><a class="header" href="#offline-forest">Offline Forest</a></h1>
<p>Forest offers an offline mode, allowing using the snapshot as the source of
chain data and not connecting to any peers. This is useful for querying the
chain's archive state without syncing, and various testing scenarios.</p>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<pre><code class="language-bash">❯ forest-tool api serve --help
Usage: forest-tool api serve [OPTIONS] [SNAPSHOT_FILES]...

Arguments:
  [SNAPSHOT_FILES]...  Snapshot input paths. Supports `.car`, `.car.zst`, and `.forest.car.zst`

Options:
      --chain &lt;CHAIN&gt;           Filecoin network chain [default: mainnet]
      --port &lt;PORT&gt;             [default: 2345]
      --auto-download-snapshot
      --height &lt;HEIGHT&gt;         Validate snapshot at given EPOCH, use a negative value -N to validate the last N EPOCH(s) starting at HEAD [default: -50]
      --genesis &lt;GENESIS&gt;       Genesis file path, only applicable for devnet
  -h, --help                    Print help
</code></pre>
<h2 id="example-serving-a-calibnet-snapshot"><a class="header" href="#example-serving-a-calibnet-snapshot">Example: serving a calibnet snapshot</a></h2>
<p>The following command will start an offline server using the latest available
snapshot, which will be downloaded automatically. The server will listen on the
default port and act as a calibnet node <em>stuck</em> at the latest snapshot's height.</p>
<pre><code class="language-bash">forest-tool api serve --chain calibnet --auto-download-snapshot
</code></pre>
<h2 id="example-serving-a-custom-snapshot-on-calibnet"><a class="header" href="#example-serving-a-custom-snapshot-on-calibnet">Example: serving a custom snapshot on calibnet</a></h2>
<p>The following command will start an offline server using a custom snapshot,
which will be loaded from the provided path. The server will listen on the
default port and act as a calibnet node <em>stuck</em> at the snapshot's
height: 1859736.</p>
<pre><code class="language-bash">❯ forest-tool api serve --chain calibnet ~/Downloads/forest_snapshot_calibnet_2024-08-08_height_1859736.forest.car.zst
2024-08-12T12:29:16.624698Z  INFO forest_filecoin::tool::offline_server::server: Configuring Offline RPC Server
2024-08-12T12:29:16.640402Z  INFO forest_filecoin::tool::offline_server::server: Using chain config for calibnet
2024-08-12T12:29:16.641654Z  INFO forest_filecoin::genesis: Initialized genesis: bafy2bzacecyaggy24wol5ruvs6qm73gjibs2l2iyhcqmvi7r7a4ph7zx3yqd4
2024-08-12T12:29:16.643263Z  INFO forest_filecoin::daemon::db_util: Populating column EthMappings from range: [322354, 1859736]
...
2024-08-12T12:29:44.218675Z  INFO forest_filecoin::tool::offline_server::server: Starting offline RPC Server
2024-08-12T12:29:44.218804Z  INFO forest_filecoin::rpc: Ready for RPC connections
</code></pre>
<p>The server can then be queried using <code>forest-cli</code> or raw requests.</p>
<pre><code class="language-bash">❯ curl --silent -X POST -H "Content-Type: application/json" \
             --data '{"jsonrpc":"2.0","id":2,"method":"Filecoin.ChainHead","param":"null"}' \
             "http://127.0.0.1:2345/rpc/v0" | jq
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "Cids": [
      {
        "/": "bafy2bzaceafill2bfzjwfq7o5x5idqe2odrriz5n4pup5xfrbsdrzjsa6mspk"
      }
    ],
    "Blocks": [
      {
      ...
      }
    ],
    "Height": 1859736
  }
}
</code></pre>
<h2 id="example-usage-on-a-devnet"><a class="header" href="#example-usage-on-a-devnet">Example: usage on a devnet</a></h2>
<p>The devnet case is a bit more complex, as the genesis file and the network name
need to be provided. If no snapshots are provided, the server will start at the
genesis block.</p>
<pre><code class="language-bash">forest-tool api serve --chain localnet-55c7758d-c91a-41eb-94a2-718cb4601bc5 --genesis /lotus_data/devgen.car
</code></pre>
<p>The server can be later queried:</p>
<pre><code class="language-bash">❯ curl --silent -X POST -H "Content-Type: application/json" \
             --data '{"jsonrpc":"2.0","id":2,"method":"Filecoin.StateGetNetworkParams","param":"null"}' \
             "http://127.0.0.1:2345/rpc/v0" | jq
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "NetworkName": "localnet-55c7758d-c91a-41eb-94a2-718cb4601bc5",
    "BlockDelaySecs": 4,
    "ConsensusMinerMinPower": "2040",
    "SupportedProofTypes": [
      0,
      1
    ],
    "PreCommitChallengeDelay": 10,
    "ForkUpgradeParams": {
      "UpgradeSmokeHeight": -2,
      ...
      "UpgradeWaffleHeight": 18
    },
    "Eip155ChainID": 31415926
  }
}
</code></pre>
<p>Note that the network name will vary depending on the genesis file used.</p>
<p>⚠️ The offline server is unable to append blocks to the chain at the moment of
writing. See <a href="https://github.com/ChainSafe/forest/issues/4598">#4598</a> for
details and updates. This means that starting the server only with a genesis
file won't be very useful, as the chain will be stuck at the genesis block.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="developer-documentation"><a class="header" href="#developer-documentation">Developer documentation</a></h1>
<p>In this section you will find resources targeted for Forest developers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-application-architecture-of-forest-largely-mirrors-that-of-lotus"><a class="header" href="#the-application-architecture-of-forest-largely-mirrors-that-of-lotus">The application architecture of <code>forest</code> largely mirrors that of <code>lotus</code>:</a></h1>
<ul>
<li>There is a core
<a href="https://github.com/ChainSafe/forest/blob/v0.8.2/blockchain/state_manager/src/lib.rs"><code>StateManager</code></a>,
which accepts:
<ul>
<li><a href="https://github.com/ChainSafe/forest/blob/v0.8.2/node/rpc/src/lib.rs">RPC calls</a></li>
<li><a href="https://github.com/ChainSafe/forest/blob/v0.8.2/blockchain/chain_sync/src/lib.rs">Filecoin peer state</a></li>
</ul>
</li>
</ul>
<p>For more information, see the
<a href="https://github.com/filecoin-project/lotus/blob/v1.23.0/documentation/en/architecture/architecture.md">lotus documentation</a>,
including, where relevant, the
<a href="https://spec.filecoin.io/">filecoin specification</a>.</p>
<p>(These also serve as a good introduction to the general domain, assuming a basic
familiarity with blockchains.)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contribuiting-to-forest"><a class="header" href="#contribuiting-to-forest">Contribuiting to Forest</a></h1>
<h2 id="submitting-code"><a class="header" href="#submitting-code">Submitting Code</a></h2>
<p>Please use <code>make lint</code> to ensure code is properly formatted, license headers are
present, and to run the linter.</p>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<p>Please use the following guidelines while documenting code. Except for inline
comments, these should all be doc comments (<code>///</code>).</p>
<h3 id="methodsfunctions"><a class="header" href="#methodsfunctions">Methods/Functions</a></h3>
<ul>
<li>At least a brief description</li>
</ul>
<h3 id="structs"><a class="header" href="#structs">Structs</a></h3>
<ul>
<li>At least a brief description</li>
</ul>
<h3 id="traits"><a class="header" href="#traits">Traits</a></h3>
<ul>
<li>At least a brief description</li>
</ul>
<h3 id="enums"><a class="header" href="#enums">Enums</a></h3>
<ul>
<li>At least a brief overall description.</li>
<li>All variants should have a brief description.</li>
</ul>
<h3 id="inline-comments"><a class="header" href="#inline-comments">Inline Comments</a></h3>
<ul>
<li>Any complicated logic should include in-line comments (<code>//</code>)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="database-migrations"><a class="header" href="#database-migrations">Database migrations</a></h1>
<h2 id="problem"><a class="header" href="#problem">Problem</a></h2>
<p>Storing data is one of the prime purposes of Forest, and we often play around
with different layouts and database settings.</p>
<p>Up until now, we've been okay with deleting the database and starting from a
fresh snapshot. This was annoying but acceptable since we never had more than
100GiB of data. Going forward, we'll be setting up nodes with ~14 TiB of data,
and we want them to not require any maintenance when new versions of Forest are
released.</p>
<h2 id="proposed-solution"><a class="header" href="#proposed-solution">Proposed solution</a></h2>
<p>High-level flowchart:</p>
<pre><code class="language-mermaid">flowchart TB
    RunForest[/Forest run/] --&gt; DevMode{Development mode?}
    DevMode ==&gt;|no| SameDbVersionExists{Same DB version already exists?}
    DevMode --&gt;|yes| DevDbExists{Development DB exists?}
    subgraph development mode
        DevDbExists --&gt;|no| CreateDevDb[Create development DB]
        DevDbExists --&gt;|yes| OpenDevDb[Open development DB]
    end
    SameDbVersionExists --&gt;|yes| Finish[Finish]
    SameDbVersionExists ==&gt;|no| OlderDbVersionExists{Older DB version exists and migration possible?}:::Yellow
    OlderDbVersionExists --&gt;|no| CreateVersionedDb
    OlderDbVersionExists ==&gt;|yes| RunMigration[Run migration]:::Yellow
    RunMigration ==&gt; RunChecks[Run checks]:::Yellow
    RunChecks ==&gt; ChecksPassing{Checks passing?}:::Green
    ChecksPassing --&gt;|yes| Finish
    ChecksPassing --&gt;|no| CreateVersionedDb
    CreateVersionedDb --&gt; Finish
    CreateDevDb --&gt; Finish
    OpenDevDb --&gt; Finish[/Run daemon/]

classDef Green stroke:#0f0,stroke-width:2px;
classDef Yellow stroke:#ff0,stroke-width:2px;
</code></pre>
<p>Expected migration path is marked in bold.</p>
<h3 id="scenarios-to-cover"><a class="header" href="#scenarios-to-cover">Scenarios to cover</a></h3>
<h4 id="scenario-1-no-db-exists"><a class="header" href="#scenario-1-no-db-exists">Scenario 1: No DB exists</a></h4>
<p>A new DB is created and the daemon is started. If the development environment
variable, the database is created under <code>&lt;DATA_DIR&gt;/&lt;NETWORK&gt;/paritydb-dev</code>.
Otherwise, it is created under <code>&lt;DATA_DIR&gt;/&lt;NETWORK&gt;/paritydb-vX.Y.Z</code>.</p>
<h4 id="scenario-2-db-exists-but-is-not-the-latest-version-migration"><a class="header" href="#scenario-2-db-exists-but-is-not-the-latest-version-migration">Scenario 2: DB exists, but is not the latest version (migration!)</a></h4>
<p>An attempt to migrate the database is made, provided that the migration is
defined. If the migration is not defined, a warning is displayed and Forest will
start under a new database. Alternatively, we can choose to fail the migration
and not start the daemon.</p>
<p>If migration succeeds and the checks are passing, the database is atomically
renamed to <code>&lt;DATA_DIR&gt;/&lt;NETWORK&gt;/paritydb-vX.Y.Z</code> and the daemon is started. If
the checks are not passing, the migration is cancelled, and we start the daemon
under a new database.</p>
<h4 id="scenario-3-db-exists-and-is-the-latest-version"><a class="header" href="#scenario-3-db-exists-and-is-the-latest-version">Scenario 3: DB exists and is the latest version</a></h4>
<p>The daemon is started and the database path is not changed.</p>
<h4 id="scenario-4-db-exists-and-is-newer-than-the-daemon-version"><a class="header" href="#scenario-4-db-exists-and-is-newer-than-the-daemon-version">Scenario 4: DB exists and is newer than the daemon version</a></h4>
<p>The daemon is started with a new database as migrating down is not supported.</p>
<h3 id="use-cases"><a class="header" href="#use-cases">Use cases</a></h3>
<h4 id="developer-switching-to-newer-branch-development-mode"><a class="header" href="#developer-switching-to-newer-branch-development-mode">Developer, switching to newer branch (development mode)</a></h4>
<p>An attempt will be made to open the database, it may succeed or not.</p>
<h4 id="developer-switching-to-older-branch-development-mode"><a class="header" href="#developer-switching-to-older-branch-development-mode">Developer, switching to older branch (development mode)</a></h4>
<p>We don't support migrating down. An attempt will be made to open the database,
it may succeed or not. A possible <em>development</em> database is also the
<code>&lt;DATA_DIR&gt;/&lt;NETWORK&gt;/paritydb</code> database (what we currently use).</p>
<h4 id="ci-accepting-pr-with-a-breaking-change"><a class="header" href="#ci-accepting-pr-with-a-breaking-change">CI, accepting PR with a breaking change</a></h4>
<p>To test that a breaking change is detected and handled correctly, we can use
Forest image with the <code>latest</code> tag.</p>
<ol>
<li>Run Forest with the <code>latest</code> tag, sync up to the HEAD. We can use volumes to
share the database between runs.</li>
<li>Run Forest from the current branch (re-using the database), sync up to the
HEAD.</li>
</ol>
<p>If the database is compatible or a migration is successful, the second run
should be able to sync up to the HEAD. Otherwise, the second run should fail.</p>
<h4 id="ci-sync-check"><a class="header" href="#ci-sync-check">CI, sync check</a></h4>
<p>Sync check is constantly checking new <code>edge</code> versions of Forest. It may be that
there are several breaking changes before we release a new version. Given that
supporting this may be a lot of work (reverts are permitted on <code>main</code>) and that
we are not sure if we want to support this, we can simply use the development
mode database for this.</p>
<h4 id="user-upgrading-to-a-new-version"><a class="header" href="#user-upgrading-to-a-new-version">User, upgrading to a new version</a></h4>
<p>See scenario 2.</p>
<h4 id="user-starting-a-new-node-from-scratch"><a class="header" href="#user-starting-a-new-node-from-scratch">User, starting a new node from scratch</a></h4>
<p>See Scenario 4.</p>
<h3 id="migration"><a class="header" href="#migration">Migration</a></h3>
<pre><code class="language-mermaid">flowchart TB
    MigrationExists{Migration exists?} --&gt;|no| Fail[/Fail/]
    MigrationExists --&gt;|yes| RunMigration[Run migration]
    RunMigration --&gt; RunChecks[Run checks]
    RunChecks --&gt; ChecksPassing{Checks passing?}
    ChecksPassing --&gt;|yes| PersistDb[Persist DB] --&gt; Finish[/Finish/]
    ChecksPassing --&gt;|no| Fail
</code></pre>
<p>Note: migration is run on a temporary database. If the checks are passing, the
result is persisted.</p>
<h3 id="checking-if-migration-exists"><a class="header" href="#checking-if-migration-exists">Checking if migration exists</a></h3>
<p>We can use a graph to check if a migration exists. There doesn't have to be a
direct path between two versions.</p>
<pre><code class="language-mermaid">flowchart TB
    subgraph Basic with one version
        Version1 -.- Version2
        Version1 ==&gt;|migration| Version2
    end
    subgraph Multiple versions direct migration
        Version3 -.- Version4 -.- Version5
        Version3 ==&gt;|migration| Version5
    end
    subgraph Multiple versions indirect migration
        Version6 -.- Version7 -.- Version8
        Version6 ==&gt;|migration| Version7 ==&gt;|migration| Version8
    end
   linkStyle 1,4,7,8 stroke:#0f0,stroke-width:4px
</code></pre>
<p>Note: a migration may not exist by design.</p>
<h3 id="example-migration"><a class="header" href="#example-migration">Example migration</a></h3>
<p>Let's consider the most basic change, a modification in the column settings. A
possible algorithm for the migration is:</p>
<pre><code>for each column in the current database:
  for each entry in the column:
    save the entry to a temporary database

if all entries are saved successfully:
  rename the temporary database to the new database
  remove the old database
else:
  fail the migration
</code></pre>
<h3 id="performance-considerations"><a class="header" href="#performance-considerations">Performance considerations</a></h3>
<p>The migration is run on a temporary database. This means that it requires twice
the regular disk space.</p>
<h3 id="potential-improvements"><a class="header" href="#potential-improvements">Potential improvements</a></h3>
<p>In development mode, we could potentially try to use the existing versioned
database.</p>
<div style="break-before: page; page-break-before: always;"></div><p>There are often cases where the jobs fail at the CI and not locally, which tends
to be cumbersome to debug. Also, when developing an integration test, it is
useful to get immediate feedback instead of relying on Github Actions (which, on
a side note, are sometimes down).</p>
<p>There is a <a href="https://github.com/nektos/act">tool called Act</a> that allows you to
run Github Actions locally. Given the complexity of Forest's CI, it is difficult
to run the whole CI locally, but it is feasible to run a single or set of jobs.
This is useful to debug a failing job, or to run an integration test locally.
Note that while Github Actions are run in fully virtualized environments, Act
runs them in Docker containers. This means that the environment is not exactly
the same, but it is close enough to be useful. In practice, we need some
<em>tricks</em> to make it work.</p>
<h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>To install Act, follow the instructions specific to your OS in the
<a href="https://github.com/nektos/act#installation-through-package-managers">Act repository</a>.</p>
<p>On the first run, <code>act</code> will ask you to pick the image size. Either choose the
biggest one (it's ~60GiB unzipped) or the medium one. The large one should have
fewer issues with the missing software, but it will take longer to download and
is based on an older Ubuntu base. You can always edit this later in
<code>$HOME/.actrc</code>.</p>
<h1 id="challenges"><a class="header" href="#challenges">Challenges</a></h1>
<p>Let's consider running an integration test. At the time of writing, the usual
workflow looks like this:</p>
<ol>
<li>Build Forest daemon and CLI in one job.</li>
<li>Upload the artifacts to GH.</li>
<li>In another job, download the artifacts to the test runner.</li>
<li>Run the integration test.</li>
</ol>
<p>There are some hurdles to overcome.</p>
<h2 id="sccache"><a class="header" href="#sccache">sccache</a></h2>
<h3 id="disabling-sccache"><a class="header" href="#disabling-sccache">Disabling sccache</a></h3>
<p>We have it everywhere where compilation is involved. It is not installed in the
Act container, so we need to comment all such jobs out. It's not really
mandatory if the <code>continue-on-error</code> is set to <code>true</code> but it does unclutter the
logs.</p>
<pre><code class="language-yaml">- name: Setup sccache
  uses: mozilla-actions/sccache-action@v0.0.3
  timeout-minutes: ${{ fromJSON(env.CACHE_TIMEOUT_MINUTES) }}
  continue-on-error: true
</code></pre>
<p>A mandatory step is to disable the <code>sccache</code> in the compiler variables. Comments
those overrides out.</p>
<pre><code class="language-yaml">RUSTC_WRAPPER: "sccache"
CC: "sccache clang"
CXX: "sccache clang++"
</code></pre>
<h3 id="installing-sccache"><a class="header" href="#installing-sccache">Installing sccache</a></h3>
<p>Alternatively, if debugging <code>sccache</code> itself you can set it up yourself. Create
your own Space in Digital Ocean. Create a <code>.env</code> file and add the following
variables there:</p>
<pre><code>SCCACHE_BUCKET=&lt;my-personal-bucket&gt; SCCACHE_REGION=auto
SCCACHE_ENDPOINT=&lt;my-personal-endpoint&gt;
</code></pre>
<p>Grab your Digital Ocean access token and add it to a secrets file. Make sure you
don't commit it to the project!</p>
<pre><code>AWS_ACCESS_KEY_ID=&lt;my-personal-access-key-id&gt;
AWS_SECRET_ACCESS_KEY=&lt;my-personal-secret-access-key&gt;
</code></pre>
<p>You will be able to use those files with the <code>--env-file</code> and <code>--secret-file</code>
flags.</p>
<p>On top of that, you will need to manually install <code>sccache</code> in the container.
Grab the URL of the latest release from the
<a href="https://github.com/mozilla/sccache/releases">sccache repository</a> and put it as
a step in the job that needs it.</p>
<pre><code class="language-shell">wget https://github.com/mozilla/sccache/releases/download/v0.5.3/sccache-v0.5.3-x86_64-unknown-linux-musl.tar.gz
tar -zxf sccache-v0.5.3-x86_64-unknown-linux-musl.tar.gz
sudo mv sccache-v0.5.3-x86_64-unknown-linux-musl/sccache /usr/bin/ &amp;&amp; sudo chmod +x /usr/bin/sccache
</code></pre>
<h2 id="uploadingdownloading-artifacts"><a class="header" href="#uploadingdownloading-artifacts">Uploading/downloading artifacts</a></h2>
<p>If your job uses one of those actions, you can support it with the
<code>--artifact-server-path &lt;temporary-path</code>. Make sure the directory is created
before running the job.</p>
<h2 id="missing-commands"><a class="header" href="#missing-commands">Missing commands</a></h2>
<p>Some commands are not available in the Act container. You can either install
them manually or disable such steps. For example, the <code>lscpu</code> command is not
available.</p>
<h2 id="missing-certificates"><a class="header" href="#missing-certificates">Missing certificates</a></h2>
<p>It may happen for some downloads. You can disable the step or install the
certificates manually. For example, the <code>rustup</code> command fails because of that.
You can install the certificates with the following command:</p>
<pre><code class="language-shell">apt-get install -y ca-certificates
</code></pre>
<p>If this does not work, you can try to install the certificates manually, for
example, if there are issues with
<a href="https://letsencrypt.org/certificates/">LetsEncrypt</a>, you try downloading a new
root certificate.</p>
<pre><code class="language-shell">wget https://letsencrypt.org/certs/isrgrootx1.pem
mv isrgrootx1.pem /usr/local/share/ca-certificates/isrgrootx1.crt update-ca-certificates --fresh
</code></pre>
<h2 id="cargo-not-in-path"><a class="header" href="#cargo-not-in-path"><code>cargo</code> not in PATH</a></h2>
<p>Add it to the PATH manually before running the command that requires it:</p>
<pre><code class="language-yaml">run: |
  export PATH="${HOME}/.cargo/bin:${PATH}"
  make install
</code></pre>
<h2 id="rebuilding-forest-from-scratch"><a class="header" href="#rebuilding-forest-from-scratch">Rebuilding Forest from scratch</a></h2>
<p>You can avoid re-building the entire project all the time either by re-using the
container with <code>--reuse</code> or by modifying the job to not depend on it and just
download the artifacts.</p>
<h1 id="example-run"><a class="header" href="#example-run">Example run</a></h1>
<p>After all the remarks above are addressed, you can run the job locally. For
example, to run the integration test for the CLI:</p>
<pre><code class="language-shell">act --secret-file act-secrets.env --env-file act.env -W .github/workflows/forest.yml -j forest-cli-check --artifact-server-path /tmp/artifacts/  --reuse
</code></pre>
<p>Assuming you don't want to use <code>sccache</code> and have disabled it, you can run:</p>
<pre><code class="language-shell">act -W .github/workflows/forest.yml -j forest-cli-check --artifact-server-path /tmp/artifacts/  --reuse
</code></pre>
<p>Shortened output:</p>
<pre><code>❯ act --secret-file ../forest/act-secrets.env --env-file ../forest/act.env -W .github/workflows/forest.yml -j forest-cli-check --artifact-server-path /tmp/artifacts/  --reuse -q
INFO[0000] Start server on http://192.168.1.10:34567
[Integration tests/Build Ubuntu] 🚀  Start image=catthehacker/ubuntu:act-latest
[Integration tests/Build Ubuntu]   🐳  docker pull image=catthehacker/ubuntu:act-latest platform= username= forcePull=false
[Integration tests/Build Ubuntu]   🐳  docker create image=catthehacker/ubuntu:act-latest platform= entrypoint=["/usr/bin/tail" "-f" "/dev/null"] cmd=[]
[Integration tests/Build Ubuntu]   🐳  docker run image=catthehacker/ubuntu:act-latest platform= entrypoint=["/usr/bin/tail" "-f" "/dev/null"] cmd=[]
[Integration tests/Build Ubuntu]   ☁  git clone 'https://github.com/actions/upload-artifact' # ref=v3
[Integration tests/Build Ubuntu] ⭐ Run Main Show IP
[Integration tests/Build Ubuntu]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/0] user= workdir=
[Integration tests/Build Ubuntu]   ✅  Success - Main Show IP
[Integration tests/Build Ubuntu] ⭐ Run Main Checkout Sources
[Integration tests/Build Ubuntu]   🐳  docker cp src=/home/rumcajs/prj/forest/. dst=/home/rumcajs/prj/forest
[Integration tests/Build Ubuntu]   ✅  Success - Main Checkout Sources
[Integration tests/Build Ubuntu] ⭐ Run Main Install Apt Dependencies
[Integration tests/Build Ubuntu]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2] user= workdir=
[Integration tests/Build Ubuntu]   ✅  Success - Main Install Apt Dependencies
[Integration tests/Build Ubuntu] ⭐ Run Main Cargo Install
[Integration tests/Build Ubuntu]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/3] user= workdir=
[Integration tests/Build Ubuntu]   ✅  Success - Main Cargo Install
[Integration tests/Build Ubuntu] ⭐ Run Main actions/upload-artifact@v3
[Integration tests/Build Ubuntu]   🐳  docker cp src=/home/rumcajs/.cache/act/actions-upload-artifact@v3/ dst=/var/run/act/actions/actions-upload-artifact@v3/
[Integration tests/Build Ubuntu]   🐳  docker exec cmd=[node /var/run/act/actions/actions-upload-artifact@v3/dist/index.js] user= workdir=
[Integration tests/Build Ubuntu]   ✅  Success - Main actions/upload-artifact@v3
[Integration tests/Build Ubuntu] 🏁  Job succeeded
[Integration tests/Forest CLI checks] 🚀  Start image=catthehacker/ubuntu:act-latest
[Integration tests/Forest CLI checks]   🐳  docker pull image=catthehacker/ubuntu:act-latest platform= username= forcePull=false
[Integration tests/Forest CLI checks]   🐳  docker create image=catthehacker/ubuntu:act-latest platform= entrypoint=["/usr/bin/tail" "-f" "/dev/null"] cmd=[]
[Integration tests/Forest CLI checks]   🐳  docker run image=catthehacker/ubuntu:act-latest platform= entrypoint=["/usr/bin/tail" "-f" "/dev/null"] cmd=[]
[Integration tests/Forest CLI checks]   ☁  git clone 'https://github.com/actions/download-artifact' # ref=v3
[Integration tests/Forest CLI checks] ⭐ Run Main Checkout Sources
[Integration tests/Forest CLI checks]   🐳  docker cp src=/home/rumcajs/prj/forest/. dst=/home/rumcajs/prj/forest
[Integration tests/Forest CLI checks]   ✅  Success - Main Checkout Sources
[Integration tests/Forest CLI checks] ⭐ Run Main actions/download-artifact@v3
[Integration tests/Forest CLI checks]   🐳  docker cp src=/home/rumcajs/.cache/act/actions-download-artifact@v3/ dst=/var/run/act/actions/actions-download-artifact@v3/
[Integration tests/Forest CLI checks]   🐳  docker exec cmd=[node /var/run/act/actions/actions-download-artifact@v3/dist/index.js] user= workdir=
[Integration tests/Forest CLI checks]   ✅  Success - Main actions/download-artifact@v3
[Integration tests/Forest CLI checks]   ⚙  ::set-output:: download-path=/root/.cargo/bin
[Integration tests/Forest CLI checks] ⭐ Run Main Set permissions
[Integration tests/Forest CLI checks]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2] user= workdir=
[Integration tests/Forest CLI checks]   ✅  Success - Main Set permissions
[Integration tests/Forest CLI checks] ⭐ Run Main install CA certificates
[Integration tests/Forest CLI checks]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/3] user= workdir=
[Integration tests/Forest CLI checks]   ✅  Success - Main install CA certificates
[Integration tests/Forest CLI checks] ⭐ Run Main Make sure everything is in PATH
[Integration tests/Forest CLI checks]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/4] user= workdir=/root/.cargo/bin/
[Integration tests/Forest CLI checks]   ✅  Success - Main Make sure everything is in PATH
[Integration tests/Forest CLI checks] ⭐ Run Main forest-cli check
[Integration tests/Forest CLI checks]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/5] user= workdir=
[Integration tests/Forest CLI checks]   ✅  Success - Main forest-cli check
[Integration tests/Forest CLI checks] 🏁  Job succeeded
</code></pre>
<h1 id="caveats"><a class="header" href="#caveats">Caveats</a></h1>
<h2 id="privileges"><a class="header" href="#privileges">Privileges</a></h2>
<p>By default, <code>act</code> runs jobs as <code>root</code>. Github Actions run under a regular
account (with <code>sudo</code> privileges). Use <code>sudo</code> for installing dependencies, even
if locally it works without it.</p>
<h2 id="docker-buildkit"><a class="header" href="#docker-buildkit">Docker BuildKit</a></h2>
<p>It is likely that you have the Docker BuildKit enabled on your system by
default. It is not true for GH Actions. To use some of its features, you will
need to explicitly put it before other Docker steps:</p>
<pre><code class="language-yaml">- name: Set up Docker Buildx
  uses: docker/setup-buildx-action@v3
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-for-mainnet-compatibility"><a class="header" href="#testing-for-mainnet-compatibility">Testing for Mainnet Compatibility</a></h1>
<p>Forest development can be like hitting a moving target and sometimes Forest
falls behind the network. This document should serve as a way to easily identify
if Forest can sync all the way up to the network head using a simple
step-by-step process.</p>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<p>Some command-line tools and software is required to follow this guide.</p>
<ul>
<li>A fresh copy of the Forest repository that has been built</li>
<li>Lotus installed</li>
<li>curl (to download snapshots)</li>
<li>sha256sum (optional, used to verify snapshot integrity)</li>
</ul>
<h2 id="grab-a-snapshot-and-run-forest"><a class="header" href="#grab-a-snapshot-and-run-forest">Grab a snapshot and run Forest</a></h2>
<p>Refer to the mdbook documentation on how to download a snapshot and run forest</p>
<p>Warning: FileCoin snapshots as of this writing are over 75GB. Verify you have
enough space on your system to accommodate these large files.</p>
<ul>
<li>Use <code>make mdbook</code> in Forest's root directory</li>
<li>Open <code>http://localhost:3000</code></li>
<li>Navigate to <code>2. Basic Usage</code> in the menu on the right</li>
<li>Scroll down to <code>Forest Import Snapshot Mode</code></li>
</ul>
<h2 id="let-forest-sync"><a class="header" href="#let-forest-sync">Let Forest sync</a></h2>
<p>This step may take a while. We want Forest to get as far along in the syncing
process as it can get. If it syncs up all the way to the network head, CONGRATS!
Forest is up to date and on mainnet. Otherwise, Forest is not on mainnet.</p>
<p>If Forest starts to error and can't get past a block while syncing. Make note of
which block it is. We can use that block to help debug any potential state
mismatches.</p>
<h2 id="is-forest-on-the-latest-network-version"><a class="header" href="#is-forest-on-the-latest-network-version">Is Forest on the latest network version?</a></h2>
<p>Something easy to check is if Forest is on the latest Filecoin network version.
A repository exists where we can see all of the released network versions
<a href="https://github.com/filecoin-project/tpm/tree/master/Network%20Upgrades">here</a>.
Navigate the codebase to see mention of the latest network upgrade. If a
snapshot fails to sync at a certain epoch, it's entirely possible that the
snapshot was behind an epoch when a version upgrade started. Grab a new snapshot
by referring to the mdbook documentation.</p>
<h2 id="debugging-state-mismatches"><a class="header" href="#debugging-state-mismatches">Debugging State Mismatches</a></h2>
<p>Statediffs can only be printed if we import a snapshot containing the stateroot
data from Lotus. This means there will not be a pretty statediff if Forest is
already synced to the network when the stateroot mismatch happens. By default,
snapshots only contain stateroot data for the previous 2000 epochs. So, if you
have a statediff at epoch X, download a snapshot for epoch X+100 and tell Forest
to re-validate the snapshot from epoch X.</p>
<p>Steps to print a state-diff:</p>
<ol>
<li>Note the epoch of the state-root mismatch. State-roots can only be checked
for the parents of a tipset so the failing epoch may be 1 higher than you
think.</li>
<li>Download a recent snapshot dated <em>before</em> the failing epoch.</li>
<li>Import the snapshot into Lotus and sync to HEAD.</li>
<li>Export a new snapshot 100 epochs <em>after</em> the failing epoch.</li>
<li>Convert the <code>.car.zst</code> file to <code>.forest.car.zst</code> with:
<code>forest-tool snapshot compress {snapshot.car.zst}</code></li>
<li>Use the <code>forest-tool</code> binary to print the state-diff:
<code>forest-tool archive diff {snapshot.forest.car.zst} --epoch {failing_epoch}</code></li>
</ol>
<h2 id="fvm-traces"><a class="header" href="#fvm-traces">FVM Traces</a></h2>
<p>Within FVM, we can enable tracing to produce execution traces. Given an
offending epoch, we can produce them both for Forest and for Lotus to find
mismatches.</p>
<p>To confirm: the execution traces format is not uniform across implementations,
so it takes a certain amount of elbow grease to find the differences. Lotus is
capable of spitting this out in JSON for nice UX</p>
<h2 id="dated-resources"><a class="header" href="#dated-resources">Dated resources</a></h2>
<p>For more (but dated) information, see
<a href="https://www.notion.so/chainsafe/Interop-debugging-6adabf9222d7449bbfeaacb1ec997cf8">this document.</a></p>
<div style="break-before: page; page-break-before: always;"></div><p>In case of memory leaks, either coming from <em>unsafe</em> libraries or just Forest
pushing shamelessly into some collection, it is useful to not guess where the
leak happened but to use proper tooling.</p>
<h1 id="heaptrack"><a class="header" href="#heaptrack"><a href="https://github.com/KDE/heaptrack">HeapTrack</a></a></h1>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<p>Either build it with the instructions provided in the repository or download a
ready AppImage, e.g. from
<a href="https://invent.kde.org/sdk/heaptrack/-/releases">here</a>. You may not want to use
the <code>heaptrack</code> available in your OS packages as it may be a bit outdated.</p>
<h2 id="preparation"><a class="header" href="#preparation">Preparation</a></h2>
<p>To get the most out of the tool, you may want to add debug information to the
binary, regardless if you are running it in release or debug mode.</p>
<pre><code class="language-toml">[profile.dev]
debug = 2

[profile.release]
debug = 2
</code></pre>
<h2 id="usage-2"><a class="header" href="#usage-2">Usage</a></h2>
<p>You can grab the trace on your host machine or in a VPS (e.g. Digital Ocean
Droplet).</p>
<p>Start tracing with <code>heaptrack &lt;normal forest command&gt;</code>, e.g.</p>
<pre><code>heaptrack target/release/forest --encrypt-keystore=false --target-peer-count 50 --chain calibnet --import-snapshot forest_snapshot.car
</code></pre>
<p>This will push traces to a file, e.g. <code>heaptrack.forest.12345.gz</code>. The longer
your process will be running, the bigger it will get, so double check your free
space before leaving it overnight.</p>
<p>Now analyze the trace. You can do it after Forest has e.g. crashed due to OOM or
even during its execution. If you were capturing traces in a Droplet, copy the
file to your host, e.g.
<code>scp chainsafe@123.45.66.77:/home/chainsafe/heaptrack.forest.12345.gz .</code>.</p>
<p>Depending on the size of the trace, it may take a while (but there is a nice
progress bar so you will know if you can grab a coffee in the meantime).</p>
<pre><code>heaptrack --analyze heaptrack.forest.12345.gz
</code></pre>
<h3 id="summary"><a class="header" href="#summary">Summary</a></h3>
<p>Here we can see memory usage overview. Keep in mind that <em>leaks</em> here are not
necessarily leaks - it's just memory that hasn't been yet freed. A global cache
would always show as a leak.</p>
<p>While most of the potential <em>culprits</em> are not necessarily interesting (e.g.
<code>alloc::*</code>) because even a <code>String</code> constructor calls them, we immediately see
that among specific ones, it's the <code>rocksdb</code> that gets into the spotlight.</p>
<p><img src="developer_documentation/heaptrack/summary.png" alt="summary" /></p>
<h3 id="bottom-up"><a class="header" href="#bottom-up">Bottom-up</a></h3>
<p>View in which you see <em>low-level</em> methods first. In such view, the first methods
would almost always be allocator methods, finally unwinding into <code>main</code>.</p>
<p><img src="developer_documentation/heaptrack/bottom_up.png" alt="bottom-up" /></p>
<h3 id="callercallee"><a class="header" href="#callercallee">Caller/callee</a></h3>
<p>All the methods called along with their allocations, where one can easily
navigate between their callers and callees, also showing you the location in
code (you can configure <code>heaptrack</code> to take you to that code with
<code>Settings/Code Navigation</code>). Most useful tab when you delve into the details.</p>
<p><img src="developer_documentation/heaptrack/caller_callee.png" alt="caller-callee" /></p>
<h3 id="top-down"><a class="header" href="#top-down">Top-down</a></h3>
<p>Basically an inverse of <em>Bottom-up</em> view. High-level methods first, then you can
drill down.</p>
<h3 id="flamegraph"><a class="header" href="#flamegraph">Flamegraph</a></h3>
<p>A graphical form of Bottom-up and Top-Down (you can switch). Helps with
visualizing the heavy allocators.</p>
<p><img src="developer_documentation/heaptrack/flamegraph.png" alt="flamegraph-up" /></p>
<h3 id="consumed"><a class="header" href="#consumed">Consumed</a></h3>
<p>Shows the heap memory consumption over time. Here we can notice some patterns,
e.g. what happens with memory during snapshot import, then downloading headers
and syncing.</p>
<p><img src="developer_documentation/heaptrack/consumed.png" alt="consumed" /></p>
<h3 id="allocations"><a class="header" href="#allocations">Allocations</a></h3>
<p>Shows total number of allocations over time.</p>
<h3 id="temporary-allocations"><a class="header" href="#temporary-allocations">Temporary allocations</a></h3>
<p>Shows the number of temporary allocations over time. Temporary allocation is an
allocation followed by its deallocation, i.e. there are no other allocations
in-between.</p>
<h3 id="sizes"><a class="header" href="#sizes">Sizes</a></h3>
<p>This tab will show you the allocation sizes during runtime and their frequency.
If you hover over a bar you will see that e.g. <code>LZ4_createStream</code> (most likely
used by <code>rocksdb</code>) made 5,624,180 allocations, total 92.3G, on average 14.4kB
per allocation.</p>
<p><img src="developer_documentation/heaptrack/sizes.png" alt="sizes" /></p>
<h3 id="miscellaneous"><a class="header" href="#miscellaneous">Miscellaneous</a></h3>
<ul>
<li>Keep in mind that running Forest <em>with</em> heaptrack gives a non-negligible
memory and CPU overhead. You may not be able to run mainnet node on a 16G
machine even if normally it would be fine.</li>
<li>Optimizations may play tricks on the developer, e.g. inlining functions so
they won't even appear in your trace. If you think a particular method should
have been called but for mysterious reasons it does not appear in the
analysis, you may want to put <code>#[inline(never)]</code> on top of it. Analyzing a
debug build may also be useful, but depending on where the leak happens, it
may be too slow.</li>
<li>There is a lot of noise coming from dependencies and standard library. It's
useful to mentally filter them out a bit and focus on the biggest culprits in
Forest methods. Flamegraph and caller/callee view are the most useful for
this.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="release-checklist-"><a class="header" href="#release-checklist-">Release checklist 🛂</a></h1>
<p>Forest doesn't follow a fixed schedule but releases should be expected at least
quarterly. A <em>release officer</em> is volunteered for each release, and they are
responsible for either following the checklist or, in case of absence, passing
the task to a different team member.</p>
<h2 id="prepare-the-release"><a class="header" href="#prepare-the-release">Prepare the release</a></h2>
<p>Make a pull request with the following changes:</p>
<ul>
<li>Update the CHANGELOG.md file to reflect all changes and preferably write a
small summary about the most notable updates. The changelog should follow the
design philosophy outlined <a href="https://keepachangelog.com/en/1.0.0/">here</a>. Go through the output of
<code>git log &lt;last-tag&gt;..HEAD</code> and remember that the audience of the CHANGELOG
does not have intimate knowledge of the Forest code-base. All the
changed/updated/removed features should be reasonably understandable to an
end-user.</li>
<li>Update the version of the <a href="https://github.com/ChainSafe/forest/blob/main/Cargo.toml">forest crate</a> (and any others, if applicable) to
be released. Make sure that the updated files do <strong>not</strong> contain a
<code>[patch.crates-io]</code> section, otherwise you won't be able to make a release on
<a href="https://crates.io/">crates.io</a>.</li>
<li>Run the manual tests steps outlined in the TEST_PLAN.md. Caveat: Right now
there are no manual test steps so this step can be skipped.</li>
<li>Make sure to run <code>cargo publish --dry-run</code> and include the <code>Cargo.lock</code> crate
version change in the release.</li>
</ul>
<h2 id="release-on-cratesio"><a class="header" href="#release-on-cratesio">Release on crates.io</a></h2>
<ul>
<li>Publish the new crate on crates.io according to the <a href="https://doc.rust-lang.org/cargo/reference/publishing.html">manual</a>.</li>
</ul>
<h2 id="release-on-github"><a class="header" href="#release-on-github">Release on GitHub</a></h2>
<ul>
<li>Create a <a href="https://github.com/ChainSafe/forest/releases/new">new release</a>. Click on <code>Choose a tag</code> button and create a new
one. The tag must start with a lowercase <code>v</code>, e.g., <code>v0.11.0</code>. Follow the
title convention of the previous releases, and write a small summary of the
release (similar or identical to the summary in the <a href="https://github.com/ChainSafe/forest/blob/main/CHANGELOG.md">CHANGELOG.md</a> file).
Add additional, detailed notes with <code>Generate release notes</code> button.</li>
<li>Verify that the new release contains assets for both Linux and macOS (the
assets are automatically generated and should show up after 30 minutes to an
hour).</li>
<li>🔁 If it's a new stable release (and not a backport), tag the version as
<code>latest</code> with the <a href="https://github.com/ChainSafe/forest/actions/workflows/docker-latest-tag.yml">retag action</a>.</li>
<li>Verify that the new release is available in the GitHub Container Registry. Use
<code>docker pull ghcr.io/chainsafe/forest:&lt;version&gt;</code>. Verify the tags in the
<a href="https://github.com/ChainSafe/forest/pkgs/container/forest">packages</a> list.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p>It's unclear how we can support migrations without adding a lot of code
complexity. This document is meant to shed light on the matter and illuminate a
sustainable path forward. As a start we will consider a migration going from
nv15 to nv16.</p>
<h1 id="migration-path-investigation-from-nv15-to-nv16"><a class="header" href="#migration-path-investigation-from-nv15-to-nv16">Migration path investigation from nv15 to nv16</a></h1>
<h2 id="findings"><a class="header" href="#findings">Findings</a></h2>
<ol>
<li>Actor IDs definitely changed</li>
</ol>
<p>For following actors only their CID have changed:</p>
<ul>
<li>init</li>
<li>cron</li>
<li>account</li>
<li>power</li>
<li>miner</li>
<li>paymentchannel</li>
<li>multisig</li>
<li>reward</li>
<li>verifiedregistry</li>
</ul>
<p>Those are just simple code migration.</p>
<p>For system and market actors there's both code and state changes. That's why
there is dedicated logic for their migration.</p>
<p>The system actor need to update the state tree with its new state that holds now
the <code>ManifestData</code> CID.</p>
<p>For the market actor more work is involved to upgrade actor state due to support
for UTF-8 string label encoding in deal proposals and pending proposals (see
<a href="https://github.com/filecoin-project/FIPs/blob/master/FIPS/fip-0027.md">FIP-0027</a>).</p>
<ol start="2">
<li>Some gas calculations changed?</li>
</ol>
<p>I don't think we are concerned by this. Gas metering can change at a given
protocol upgrade for one or many actors but the impact is irrelevant as it
doesn't modify blockchain data structures. Gas calculations should only impact
code and in our case the nv16 ref-fvm is already supporting the new gas changes.</p>
<ol start="3">
<li>drand calculation changed?</li>
</ol>
<p>Ditto.</p>
<ol start="4">
<li>What else changed?</li>
</ol>
<p>Nothing else as far I can see.</p>
<h2 id="open-questions"><a class="header" href="#open-questions">Open questions</a></h2>
<ul>
<li>
<p>pre-migration framework + caching: how much do we need a similar approach in
Forest? Are there other alternatives? We can definitely skip this part at
first. For information the old nv12 state migration in forest took around
13-15 secs.</p>
</li>
<li>
<p>Seen in Lotus: <code>UpgradeRefuelHeight</code>. What's Refuel for?</p>
</li>
<li>
<p>Migration logic is in spec-actors (go actors), what the future of this given
clients moved to builtin-actors (rust actors) and ref-fvm? In an ideal world
we might want a shared migration logic.</p>
</li>
<li>
<p>Implement Lite migration?</p>
<blockquote>
<p>should allow for easy upgrades if actors code needs to change but state does
not. Example provided above the function to perform all the migration
duties. Check actors_version_checklist.md for the rest of the steps.</p>
</blockquote>
</li>
<li>
<p>What are non-deferred actors in the context of a migration?</p>
</li>
<li>
<p>The <code>migrationJobResult</code> struct is using a <code>states7</code> actor instead of a
<code>states8</code> one (in go spec-actors). Typo or are there some good reasons?</p>
</li>
</ul>
<h2 id="changes-rough-proposal"><a class="header" href="#changes-rough-proposal">Changes rough proposal</a></h2>
<p>To support nv15 to nv16 migration we need to:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Make forest sync again on nv15 and be able to support multiple network
versions.</li>
<li><input disabled="" type="checkbox"/>
Understand existing forest migration framework (used in the past for nv12
migration). Can we reuse most of the code as is?</li>
<li><input disabled="" type="checkbox"/>
Implementation of the nv16 migration logic (replicating same logic as in
spec-actors).</li>
<li><input disabled="" type="checkbox"/>
Implementation of unit tests covering this migration.</li>
<li><input disabled="" type="checkbox"/>
Implementation of a migration schedule that will select the right
migration path.</li>
<li><input disabled="" type="checkbox"/>
Test migration using the exported calibnet and mainnet snapshots and
respectively measure the elapsed time and memory usage.</li>
</ul>
<h2 id="test-snapshots"><a class="header" href="#test-snapshots">Test snapshots</a></h2>
<p>For testing a calibnet migration two snapshots have been exported with Lotus:</p>
<ul>
<li>lotus_snapshot_2022-Aug-5_height_1044460.car</li>
<li>lotus_snapshot_2022-Aug-5_height_1044659.car</li>
</ul>
<p>They are respectively exported 200 and 1 epochs before the Skyr upgrade (the 200
version could be useful if we decide to implement a pre-migration like in
Lotus).</p>
<p>For testing a mainnet migration, one snapshot has been retrieved from Protocol
Labs s3 bucket using the <a href="https://github.com/kasteph/lily-shed/">lily-shed</a>
util:</p>
<ul>
<li>minimal_finality_stateroots_1955760_2022-07-05_00-00-00.car</li>
</ul>
<p>This one is 4560 epochs before. If needed we can extract closer snapshots later.</p>
<p>Those snapshots have been uploaded to our Digital Ocean Spaces.</p>
<h2 id="additional-resources-1"><a class="header" href="#additional-resources-1">Additional resources</a></h2>
<p><code>what changed</code> between versions is maintained in the
<a href="https://github.com/filecoin-project/tpm/tree/master/Network%20Upgrades">tpm repo</a>,
e.g. all the changes in
<a href="https://github.com/filecoin-project/tpm/blob/master/Network%20Upgrades/v16.md">NV15 -&gt; NV16</a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="state-migration-guide-"><a class="header" href="#state-migration-guide-">State migration guide ⏩</a></h2>
<p>This guide is intended to help to implement new state migration in the future.
It will be based on the current state migration implementation for NV18 and
NV19.</p>
<h3 id="state-migration-requirements"><a class="header" href="#state-migration-requirements">State migration requirements</a></h3>
<ul>
<li>The proper actor bundle is released for at least the test network. It should
be available on the
<a href="https://github.com/filecoin-project/builtin-actors/releases">actor bundles repository</a>.
You can verify which upgrade needs which bundle in the
<a href="https://github.com/filecoin-project/core-devs/tree/master/Network%20Upgrades">network upgrade matrix</a>.</li>
<li>The state migration should be implemented in the
<a href="https://github.com/filecoin-project/go-state-types/tree/master/builtin">Go library</a>.
This is the source of truth for the state migration. Also, we should carefully
analyze the FIPs and implement the migration based on them. In case of doubt,
we should always consider the FIPs as the source of truth and reach out to the
Lotus team if we find potential issues in their implementation.</li>
</ul>
<h3 id="development"><a class="header" href="#development">Development</a></h3>
<h4 id="import-the-actor-bundle"><a class="header" href="#import-the-actor-bundle">Import the actor bundle</a></h4>
<p>The first step is to import the actor bundle into Forest. This is done by:</p>
<ul>
<li>adding the bundle cid to the <code>HeightInfos</code> struct in the network definitions
files (e.g.,
<a href="https://github.com/ChainSafe/forest/blob/main/src/networks/calibnet/mod.rs">calibnet</a>).</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>HeightInfo {
    height: Height::Hygge,
    epoch: 322_354,
    bundle: Some(Cid::try_from("bafy2bzaced25ta3j6ygs34roprilbtb3f6mxifyfnm7z7ndquaruxzdq3y7lo").unwrap()),
}
<span class="boring">}</span></code></pre></pre>
<ul>
<li>
<p>adding the bundle manifest cid and url to the <code>ACTOR_BUNDLES</code> in the
<code>src/networks/actors_bundle.rs</code>.</p>
</li>
<li>
<p>ensuring the bundle is mirrored in Forest's DO space under
<code>https://forest-snapshots.fra1.cdn.digitaloceanspaces.com/actors/</code>.</p>
</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>"bafy2bzacecnhaiwcrpyjvzl4uv4q3jzoif26okl3m66q3cijp3dfwlcxwztwo" @ "v11.0.0" for "mainnet",
},
<span class="boring">}</span></code></pre></pre>
<h3 id="implement-the-migration"><a class="header" href="#implement-the-migration">Implement the migration</a></h3>
<p>The next step is to implement the migration itself. In this guide, we will take
the <code>translate Go code into Rust</code> approach. It's not the cleanest way to do it,
but it's the easiest. Note that the Forest state migration design is not the
same as the Lotus one (we tend to avoid code duplications), so we must be
careful when translating the code.</p>
<h4 id="create-the-migration-module"><a class="header" href="#create-the-migration-module">Create the migration module</a></h4>
<p>Create the nvXX migration module in the
<a href="https://github.com/ChainSafe/forest/tree/main/src/state_migration">state migration module</a>.
A valid approach is just to copy-paste the previous migration module and modify
it accordingly. The files that will most likely be present:</p>
<ul>
<li><code>mod.rs</code>: here we bundle our migration modules and export the final migration
function, defining the state types before and after migration, implementing
the common system migrator and the verifier</li>
<li><code>migration.rs</code>: the heart of the migration. Here we add the migration logic
for each actor. Its Go equivalent is the
<a href="https://github.com/filecoin-project/go-state-types/blob/master/builtin/v10/migration/top.go">top.go</a>,
in case of NV18,</li>
</ul>
<p>We will most likely need as many custom migrators as there are in the Go
implementation. In other terms, if you see that the Go
<a href="https://github.com/filecoin-project/go-state-types/tree/master/builtin/v10/migration">migration</a>
contains:</p>
<ul>
<li><code>eam.go</code> - Ethereum Account Manager migration,</li>
<li><code>init.go</code> - Init actor migration,</li>
<li><code>system.go</code> - System actor migration,</li>
</ul>
<p>Then our implementation will need to define those as well.</p>
<h4 id="the-actual-migration"><a class="header" href="#the-actual-migration">The actual migration</a></h4>
<p>This part will largely depend on the complexity of the network upgrade itself.
The goal is to translate the <code>MigrateStateTree</code> method from
<a href="https://github.com/filecoin-project/go-state-types/blob/master/builtin/v10/migration/top.go#L28">Go</a>
to the <code>add_nvXX_migrations</code> in the <code>migration.rs</code> file. The
<code>add_nvXX_migrations</code> method is responsible for adding all the migrations that
are needed for the network upgrade and the logic in between. Note that the
Forest version is much simpler as it doesn't contain the migration <code>engine</code>
(implemented in the base module).</p>
<p>The first thing to do is to get the current system actor state and the current
manifest. Then we will map the old actor codes to the new ones.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let state_tree = StateTree::new_from_root(store.clone(), state)?;
let system_actor = state_tree
    .get_actor(&amp;Address::new_id(0))?
    .ok_or_else(|| anyhow!("system actor not found"))?;

let system_actor_state = store
    .get_cbor::&lt;SystemStateOld&gt;(&amp;system_actor.state)?
    .ok_or_else(|| anyhow!("system actor state not found"))?;

let current_manifest = Manifest::load_with_actors(&amp;store, &amp;system_actor_state.builtin_actors, 1)?;

let new_manifest = Manifest::load(&amp;store, &amp;new_manifest, version)?;

<span class="boring">}</span></code></pre></pre>
<p>⚠️ Stay vigilant! The <code>StateTree</code> versioning is independent of the network and
actor versioning. At the time of writing, the following holds:</p>
<ul>
<li><code>StateTreeVersion0</code> - Actors version &lt; v2</li>
<li><code>StateTreeVersion1</code> - Actors version v2</li>
<li><code>StateTreeVersion2</code> - Actors version v3</li>
<li><code>StateTreeVersion3</code> - Actors version v4</li>
<li><code>StateTreeVersion4</code> - Actors version v5 up to v9</li>
<li><code>StateTreeVersion5</code> - Actors version v10 and above These are not compatible
with each other and when using a new FVM, we can only use the latest one.</li>
</ul>
<p>For actors that don't need any state migration, we can use the <code>nil_migrator</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>for (name, code) in current_manifest.builtin_actors() {
    let new_code = new_manifest.code_by_name(name)?;
    self.add_migrator(*code, nil_migrator(*new_code));
}
<span class="boring">}</span></code></pre></pre>
<p>For each actor with non-trivial migration logic, we add the migration function.
For example, for the <code>init</code> actor, we have:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>self.add_migrator(
  *current_manifest.get_init_code(),
  init::init_migrator(*new_manifest.get_init_code()),
);
<span class="boring">}</span></code></pre></pre>
<p>and we define the <code>init_migrator</code> in a separate module. This logic may include
setting some defaults on the new fields, changing the current ones to an
upgraded version and so on.</p>
<h4 id="verifier"><a class="header" href="#verifier">Verifier</a></h4>
<p>An optional (but recommended) piece of code that performs some sanity checks on
the state migration definition. At the time of writing, it checks that all
builtin actors are assigned a migration function.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let verifier = Arc::new(Verifier::default());
<span class="boring">}</span></code></pre></pre>
<h4 id="post-migration-actions"><a class="header" href="#post-migration-actions">Post-migration actions</a></h4>
<p>Some code, like creating an entirely new actor (in the case of NV18 creating EAM
and Ethereum Account actors), needs to be executed post-migration. This is done
in the post-migration actions.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>self.add_post_migrator(Arc::new(EamPostMigrator));

self.add_post_migrator(Arc::new(EthAccountPostMigrator));
<span class="boring">}</span></code></pre></pre>
<h4 id="creating-the-migration-object-and-running-it"><a class="header" href="#creating-the-migration-object-and-running-it">Creating the migration object and running it</a></h4>
<p>We take all the migrations that we have defined previously, all the
post-migration actions, and create the migration object.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut migration = StateMigration::&lt;DB&gt;::new(Some(verifier), post_migration_actions);
migration.add_nv18_migrations(blockstore.clone(), state, &amp;new_manifest_cid)?;

let actors_in = StateTree::new_from_root(blockstore.clone(), state)?;
let actors_out = StateTree::new(blockstore.clone(), StateTreeVersion::V5)?;
let new_state =
migration.migrate_state_tree(blockstore.clone(), epoch, actors_in, actors_out)?;

Ok(new_state)
<span class="boring">}</span></code></pre></pre>
<p>The new state is the result of the migration.</p>
<h3 id="use-the-migration"><a class="header" href="#use-the-migration">Use the migration</a></h3>
<p>After completing the migration, we need to invoke it at the proper height. This
is done in the <code>handle_state_migrations</code> method in the
<a href="https://github.com/ChainSafe/forest/blob/main/blockchain/state_manager/src/lib.rs">state manager</a>.
This step could be potentially done automatically in the future.</p>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<p>We currently lack a framework for properly testing the network upgrades before
they actually happen. This should change in the future.</p>
<p>For now, we can do it using a snapshot generated after the network upgrade,
e.g., 100 epochs after and validating previous epochs which should include the
upgrade height.</p>
<pre><code class="language-shell">forest --chain calibnet --encrypt-keystore false --halt-after-import --height=-200 --import-snapshot &lt;SNAPSHOT&gt;
</code></pre>
<h3 id="test-first-development"><a class="header" href="#test-first-development">Test first development</a></h3>
<p>When the Go migration code to translate from is large(e.g. nv17), it makes
development much easier to be able to attach debuggers. Follow below steps to
create simple unit tests for both Rust and Go with real calibnet or mainnet data
and attach debuggers when needed during development.</p>
<ul>
<li>
<p>Get input state cid. Run
<code>forest --chain calibnet --encrypt-keystore false --halt-after-import --height=-200 --import-snapshot &lt;SNAPSHOT&gt;</code>,
the input state cid will be in the failure messages <code>Previous state: &lt;CID&gt;</code>.
And the expected output state cid can be found in state mismatch error
messages.</p>
</li>
<li>
<p>Export input state by running
<code>forest-cli state fetch &lt;PREVIOUS_STATE_CID&gt; &lt;PREVIOUS_STATE_CID&gt;.car</code></p>
</li>
<li>
<p>Compress the car file by running <code>zstd &lt;PREVIOUS_STATE_CID&gt;.car</code></p>
</li>
<li>
<p>Move the compressed car file to data folder <code>src/state_migration/tests/data</code></p>
</li>
<li>
<p>Create a Rust test in <code>src/state_migration/tests/mod.rs</code>. Note: the output CID
does not need to be correct to attach a debugger during development.</p>
<p>Example test for nv17 on calibnet:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_nv17_state_migration_calibnet() -&gt; Result&lt;()&gt; {
    test_state_migration(
        Height::Shark,
        NetworkChain::Calibnet,
        Cid::from_str("bafy2bzacedxtdhqjsrw2twioyaeomdk4z7umhgfv36vzrrotjb4woutphqgyg")?,
        Cid::from_str("bafy2bzacecrejypa2rqdh3geg2u3qdqdrejrfqvh2ykqcrnyhleehpiynh4k4")?,
    )
    .await
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Create a Go test in <code>src/state_migration/go-test/state_migration_test.go</code>.
Note: <code>newManifestCid</code> is the bundle CID, epoch is the height that migration
happens.
<a href="https://code.visualstudio.com/docs/languages/go#_debugging">Instruction</a> on
debugging Go code in VS Code.</p>
<p>Example test for nv17 on calibnet:</p>
<pre><code class="language-go">func TestStateMigrationNV17(t *testing.T) {
  startRoot := cid.MustParse("bafy2bzacedxtdhqjsrw2twioyaeomdk4z7umhgfv36vzrrotjb4woutphqgyg")
  newManifestCid := cid.MustParse("bafy2bzacedbedgynklc4dgpyxippkxmba2mgtw7ecntoneclsvvl4klqwuyyy")
  epoch := abi.ChainEpoch(16800)

  bs := migration9Test.NewSyncBlockStoreInMemory()
  ctx := context.Background()

  loadCar(t, ctx, bs, fmt.Sprintf("%s/.local/share/forest/bundles/calibnet/bundle_Shark.car", os.Getenv("HOME")))
  loadCompressedCar(t, ctx, bs, fmt.Sprintf("../data/%s.car.zst", startRoot))

  runStateMigration(t, ctx, cbor.NewCborStore(bs), startRoot, newManifestCid, epoch)
}
</code></pre>
</li>
</ul>
<h3 id="performance-considerations-1"><a class="header" href="#performance-considerations-1">Performance considerations</a></h3>
<p>Mainnet upgrades can take a long time even on a powerful machine, due to the
size of the state. It's useful to test beforehand how long (roughly) will a
migration take to better prepare ourselves and signal potential issues to other
implementation teams.</p>
<p>One <em>trick</em> to test this is to:</p>
<ul>
<li>download any recent mainnet snapshot,</li>
<li>change the schedule for the migration to happen 10 epochs before the
snapshot's height,</li>
<li>import the snapshot (on a clean database) and validate the migration epoch (or
a range including that epoch)</li>
</ul>
<p>For example, with the scheduled migration at 3411547, we can run:</p>
<pre><code>forest --encrypt-keystore false --import-snapshot forest_snapshot_mainnet_2023-11-22_height_3411557.forest.car.zst --height=-20
</code></pre>
<p>While the migration itself should succeed, there will be a state mismatch
afterwards. This is not an issue.</p>
<pre><code>2023-12-05T15:46:37.988136Z  INFO forest_filecoin::state_migration: State migration at height Watermelon(epoch 3411547) was successful, Previous state: bafy2bzacedqswtcnhub5ea6upcjp4s7ghba5lgxri7ckezgsdxbkgnh6oyz3w, new state: bafy2bzacecxvz7jl3pt3ki4cirp4arfbmdxxcdb2ni4mzhkbbxqaug5z747gu, new state actors: bafy2bzaceb53kdtubm74czvthzah5inpejrrw7tdueajuhp3n7pbirzjwpqok. Took: 349.9679s.
2023-12-05T15:46:42.438174Z ERROR forest_filecoin::state_manager: state mismatch height=3411549 expected_state=Cid(bafy2bzacecr6ll3w6kb5cyvcsl2e5z6wqrbhaxntzaabkbqikmhuj5a7ukbxk) expected_receipt=Cid(bafy2bzacebhp2zlhpabxgquiht7cu5rqug5sxtxyfadkiijdpaxmcrhdyfs3s) actual_state=Cid(bafy2bzacecjb4tc4hub2yytxdsr7kpozdabufgsvdixqkkllg3yqv7zxujs2g) actual_receipt=Cid(bafy2bzaceaqdlwllmddokd5izwvf7isqlzglueqcw62ttyn5j3nx2hzk4ecwg)
</code></pre>
<p>While the resulting state might be incorrect (not matching what Lotus
calculated), at least we verify that the migration isn't causing OOMs and takes
reasonable amount of time.</p>
<h3 id="future-considerations"><a class="header" href="#future-considerations">Future considerations</a></h3>
<ul>
<li>Grab the actor bundles from the IPFS. This would make Forest less dependent on
the Github infrastructure.
<a href="https://github.com/ChainSafe/forest/issues/2765">Issue #2765</a></li>
<li>Consider pre-migrations as Lotus does. It is not needed at the moment (the
mainnet upgrade takes several seconds at most) but may become a bottleneck if
the migration is too heavy.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="state-migration-spike-"><a class="header" href="#state-migration-spike-">State migration spike 🛂</a></h2>
<h3 id="what-is-state-migration"><a class="header" href="#what-is-state-migration">What is state migration?</a></h3>
<p>State migration is a process where the <code>StateTree</code> contents are transformed from
an older form to a newer form. Certain Actors may need to be created or migrated
as well.</p>
<h3 id="why-do-we-need-to-migrate"><a class="header" href="#why-do-we-need-to-migrate">Why do we need to migrate?</a></h3>
<p>Migration is required when the structure of the state changes. This happens when
new fields are added or existing ones are modified. Migration is <strong>not</strong>
required in case of new behaviour.</p>
<p>In case of NV18, the <code>StateTree</code> changed from version 4 to version 5. See
https://github.com/filecoin-project/ref-fvm/pull/1062</p>
<h3 id="what-to-upgrade"><a class="header" href="#what-to-upgrade">What to upgrade?</a></h3>
<p>We need to upgrade the <code>StateTree</code> which is represented as
<code>HAMT&lt;Cid, ActorState&gt;</code> to the latest version.</p>
<p>On top of that, we need to migrate certain actors. In the case of NV18 upgrade,
it's the
<a href="https://github.com/filecoin-project/go-state-types/blob/d8fdbda2ad86de55bcde7f567c6da9c5f430c7a1/builtin/v10/migration/init.go#L32">init</a>
and
<a href="https://github.com/filecoin-project/go-state-types/blob/master/builtin/v10/migration/system.go#L24">system</a>
actor.
<a href="https://github.com/filecoin-project/go-state-types/blob/master/builtin/v10/migration/eam.go">EAM</a>
actor needs to be created.</p>
<h3 id="when-to-upgrade"><a class="header" href="#when-to-upgrade">When to upgrade?</a></h3>
<p>There is a separate upgrade schedule for each network. In Lotus, it is defined
in
<a href="https://github.com/filecoin-project/lotus/blob/dbbcf4b2ee9626796e23a096c66e67ff350810e4/chain/consensus/filcns/upgrades.go#L83">upgrades.go</a>.
In Venus, in
<a href="https://github.com/filecoin-project/venus/blob/master/pkg/fork/fork.go">fork.go</a>
which has the same structure.</p>
<p>For the case of NV18, it is defined as</p>
<pre><code class="language-go">Height:    build.UpgradeHyggeHeight,
Network:   network.Version18,
Migration: UpgradeActorsV10,
PreMigrations: []stmgr.PreMigration{{
	PreMigration:    PreUpgradeActorsV10,
	StartWithin:     60,
	DontStartWithin: 10,
	StopWithin:      5,
}},
Expensive: true,
</code></pre>
<h3 id="how-to-upgrade"><a class="header" href="#how-to-upgrade">How to upgrade?</a></h3>
<p>Iterate over the state of each actor at the given epoch and write the new state
along with any specific changes to the respective state. This involves iterating
over each of the HAMT nodes storing the state and writing them to the database.</p>
<p><a href="https://github.com/filecoin-project/lotus/blob/58900a70333a11a903cf9fe3f29e6a5c309cb000/chain/consensus/filcns/upgrades.go#L1591-L1612">Lotus upgrade method</a>
and the
<a href="https://github.com/filecoin-project/go-state-types/tree/master/builtin/v10/migration">module</a>
dedicated to Actors <code>v10</code> migration. The core logic is
<a href="https://github.com/filecoin-project/go-state-types/blob/master/builtin/v10/migration/top.go#L28">here</a>.
The same module is used by Venus.</p>
<p>Forks migrations: handled by
<a href="https://github.com/filecoin-project/lotus/blob/58900a70333a11a903cf9fe3f29e6a5c309cb000/chain/stmgr/forks.go#L42-L53">fork.go</a>
entities.</p>
<h3 id="where-to-upgrade"><a class="header" href="#where-to-upgrade">Where to upgrade?</a></h3>
<p>It should be done most likely in the apply blocks method.</p>
<p><a href="https://github.com/filecoin-project/lotus/blob/74d94af03418c799350fc0f40d3758c23cd82ab8/chain/consensus/compute_state.go#L178">Lotus</a>:</p>
<pre><code class="language-go">// handle state forks
// XXX: The state tree
pstate, err = sm.HandleStateForks(ctx, pstate, i, em, ts)
if err != nil {
	return cid.Undef, cid.Undef, xerrors.Errorf("error handling state forks: %w", err)
}
</code></pre>
<p>In
<a href="https://github.com/ChainSafe/forest/blob/main/blockchain/state_manager/src/lib.rs#L421-L424">Forest</a>
we already have a hint from the past:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if epoch_i == turbo_height {
    todo!("cannot migrate state when using FVM - see https://github.com/ChainSafe/forest/issues/1454 for updates");
}
<span class="boring">}</span></code></pre></pre>
<p>We can try with something simplistic to get it running, it's not an issue.
Afterwards we can implement a proper schedule with functors.</p>
<h3 id="challenges-1"><a class="header" href="#challenges-1">Challenges</a></h3>
<ul>
<li>Doing the state migration efficiently; we need to traverse every entry in the
state trie. Lotus does pre-migration which are filling relevant caches to
speed up the eventual full migration at the upgrade epoch. We might need to do
something like this as well; it might not be necessary for the first
iteration - depends on how performant the migration process would be in the
Forest itself.</li>
<li>No test network. While we can use existing snapshots from before the upgrade
to test state migration, it is not sustainable if we want to continuously
support calibration network. We either require a local devnet for testing
migration <strong>before</strong> they actually happen on real networks or we can try
supporting more bleeding-edge networks. The former approach is more solid, but
the latter might be easier to implement at first (and would give Forest more
testnets support which is always welcome).</li>
<li>There may be forks, so we probably need to keep the pre-migration and
post-migration state in two caches for some back and forths. This in Lotus is
handled with
<a href="https://github.com/filecoin-project/lotus/blob/f641139bf237e6e955a9a2f33cfc05ba52430b1b/chain/stmgr/forks.go#L175">HandleStateForks</a>.</li>
<li>For EAM Actor we may need some Ethereum methods we have not yet implemented.
Perhaps what <code>builtin-actors</code> and <code>ref-fvm</code> expose will be enough.</li>
</ul>
<h3 id="current-forest-implementation"><a class="header" href="#current-forest-implementation">Current Forest implementation</a></h3>
<p>For the moment Forest does not support migrations. The
<a href="https://github.com/ChainSafe/forest/blob/state-migration-spike/vm/state_migration/src/lib.rs">code</a>
that was meant for this is not used at the moment. Most probably we will be able
to utilise it.</p>
<h3 id="plan"><a class="header" href="#plan">Plan</a></h3>
<p>We should start by adding an <code>nv18</code> to the state migration
<a href="https://github.com/ChainSafe/forest/tree/state-migration-spike/vm/state_migration/src">crate</a>,
along the lines of the
<a href="https://github.com/filecoin-project/go-state-types/blob/master/builtin/v10/migration/init.go">Go equivalent</a>.
Most likely this would mean adding some missing structures, related to the <code>v10</code>
actors (Ethereum ones).</p>
<p>Then try to plug it in
<a href="https://github.com/ChainSafe/forest/blob/main/blockchain/state_manager/src/lib.rs#L421-L424">apply_blocks</a>.
This may work for calibration network. Afterwards, we will most likely need to
iterate to achieve acceptable performance for mainnet. Some ideas on how to
achieve this can be taken from Lotus/Venus, e.g., pre-migration caching.</p>
<h3 id="sources"><a class="header" href="#sources">Sources</a></h3>
<ul>
<li>Rahul's article: https://hackmd.io/@tbdrqGmwSXiPjxgteK3hMg/r1D6cVM_u</li>
<li>Lotus codebase - https://github.com/filecoin-project/lotus</li>
<li>Venus codebase - https://github.com/filecoin-project/venus</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forest-test-plan"><a class="header" href="#forest-test-plan">Forest Test Plan</a></h1>
<pre><code>Version: 1.0
Author: David Himmelstrup
Date updated: 2022-11-14
</code></pre>
<h2 id="test-objective"><a class="header" href="#test-objective">Test objective:</a></h2>
<p>The Filecoin specification is complex and changes rapidly over time. To manage
this complexity, Forest uses a rigorous testing framework, starting with
individual functions and ending with complete end-to-end validation. The goals,
in descending order of priority, are:</p>
<ul>
<li><strong>Regression detection.</strong> If Forest can no longer connect to mainnet or if any
of its features break, the development team should be automatically notified.</li>
<li><strong>No institutional/expert knowledge required.</strong> Developers can work on a
Forest subsystem without worrying about accidentally breaking a different
subsystem.</li>
<li><strong>Bug identification.</strong> If something break, the test data should narrow down
the location of the issue.</li>
</ul>
<h2 id="scope-of-testing-definition"><a class="header" href="#scope-of-testing-definition">Scope of testing definition:</a></h2>
<p>Forest testing is multifaceted and layered. The testing pipeline looks like
this:</p>
<ul>
<li><strong>Unit tests for library functions.</strong> Example: parsing a network version fails
for garbled input.</li>
<li><strong>Unit tests for CLI programs.</strong> Example: <code>forest-cli dump</code> produces a valid
configuration.</li>
<li><strong>Property tests.</strong> Example: <code>deserialize ∘ serialize = id</code> for all custom
formats.</li>
<li><strong>Network synchronization.</strong> PRs are checked against the calibration network,
the main branch is checked against the main network.</li>
<li><strong>End-to-end feature tests.</strong> Example: Network snapshots are generated daily
and hosted publicly.</li>
<li><strong>Link checking.</strong> API documentation and markdown files are checked for dead
links.</li>
<li><strong>Spell checking.</strong> API documentation is checked for spelling errors and
typos.</li>
</ul>
<p>All testing is automated and there are no additional manual checks required for
releases.</p>
<h2 id="resources--roles--responsibilities"><a class="header" href="#resources--roles--responsibilities">Resources / Roles &amp; Responsibilities:</a></h2>
<p>Testing is a team effort and everyone is expected to add unit tests, property
tests, or integration tests as part of their PR contributions.</p>
<h2 id="tools-description"><a class="header" href="#tools-description">Tools description:</a></h2>
<ul>
<li>Bug tracker: https://github.com/ChainSafe/forest/issues</li>
<li>Test Automation tools: <a href="https://nexte.st/">nextest</a>,
<a href="https://docs.rs/quickcheck/latest/quickcheck/">quickcheck</a></li>
<li>Languages: <a href="https://www.rust-lang.org/">Rust</a></li>
<li>CI/CD: <a href="https://github.com/ChainSafe/forest/actions">GitHub Actions</a></li>
<li>Version control: <a href="https://git-scm.com/">Git</a></li>
</ul>
<h2 id="deliverables"><a class="header" href="#deliverables">Deliverables:</a></h2>
<p>The only deliverable is a green checkmark. Either all tests pass and a PR may be
merged into the main branch or something is not up to spec and the PR is
blocked.</p>
<h2 id="test-environment--ci"><a class="header" href="#test-environment--ci">Test Environment &amp; CI</a></h2>
<p>Short-running tests are executed via GitHub Actions on Linux and MacOS.
Long-running tests are run on dedicated testing servers.</p>
<p>The services on the dedicated servers are described here:
https://github.com/ChainSafe/forest-iac</p>
<p>In short, the long-running tests are executed in dockerized environments with
some running one per day and some running on every commit to the main Forest
branch. At the moment, the tests are run on DigitalOcean but they can be run
from anywhere. Feedback is reported to ChainSafe's Slack server and artifacts
are uploaded to DigitalOcean Spaces.</p>
<h2 id="test-data"><a class="header" href="#test-data">Test Data:</a></h2>
<p>No private or confidential data is involved in testing. Everything is public.</p>
<h2 id="bug-template"><a class="header" href="#bug-template">Bug template:</a></h2>
<p>Bug report template is available on GitHub:
https://github.com/ChainSafe/forest/blob/main/.github/ISSUE_TEMPLATE/bug_report.md</p>
<p>The template is applied automatically when bugs are reported through GitHub.</p>
<h2 id="risk--issues"><a class="header" href="#risk--issues">Risk &amp; Issues:</a></h2>
<ul>
<li>We depend on the calibration network for testing. If this network is down, our
testing capabilities are degraded.</li>
<li>We depend on GitHub Actions for testing. If GitHub Action is unavailable,
testing will be degraded.</li>
<li>Testing against mainnet is effective for discovering issues, but not great for
identifying root causes. Finding bugs <em>before</em> syncing to mainnet is always to
be preferred.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cleaning"><a class="header" href="#cleaning">Cleaning</a></h1>
<pre><code>rm -rf ~/.genesis-sectors/ ~/.lotus-local-net/ ~/.lotus-miner-local-net/
</code></pre>
<h1 id="running-the-node-1"><a class="header" href="#running-the-node-1">Running the node:</a></h1>
<pre><code>export LOTUS_PATH=~/.lotus-local-net
export LOTUS_MINER_PATH=~/.lotus-miner-local-net
export LOTUS_SKIP_GENESIS_CHECK=_yes_
export CGO_CFLAGS_ALLOW="-D__BLST_PORTABLE__"
export CGO_CFLAGS="-D__BLST_PORTABLE__"
# For MacOS: LIBRARY_PATH=/opt/homebrew/Cellar/hwloc/2.9.1/lib
make 2k
./lotus fetch-params 2048
./lotus-seed pre-seal --sector-size 2KiB --num-sectors 2
./lotus-seed genesis new localnet.json
./lotus-seed genesis add-miner localnet.json ~/.genesis-sectors/pre-seal-t01000.json
./lotus daemon --lotus-make-genesis=devgen.car --genesis-template=localnet.json --bootstrap=false
# Keep this terminal open
</code></pre>
<h1 id="running-the-miner"><a class="header" href="#running-the-miner">Running the miner:</a></h1>
<pre><code>export LOTUS_PATH=~/.lotus-local-net
export LOTUS_MINER_PATH=~/.lotus-miner-local-net
export LOTUS_SKIP_GENESIS_CHECK=_yes_
export CGO_CFLAGS_ALLOW="-D__BLST_PORTABLE__"
export CGO_CFLAGS="-D__BLST_PORTABLE__"
./lotus wallet import --as-default ~/.genesis-sectors/pre-seal-t01000.key
./lotus-miner init --genesis-miner --actor=t01000 --sector-size=2KiB --pre-sealed-sectors=~/.genesis-sectors --pre-sealed-metadata=~/.genesis-sectors/pre-seal-t01000.json --nosync
./lotus-miner run --nosync
# Keep this terminal open
</code></pre>
<h1 id="helpers"><a class="header" href="#helpers">Helpers:</a></h1>
<pre><code>./lotus-miner info
./lotus-miner sectors list
</code></pre>
<h1 id="send-data-to-miner"><a class="header" href="#send-data-to-miner">Send data to miner:</a></h1>
<pre><code>./lotus client query-ask t01000
./lotus client import LICENSE-APACHE
./lotus client deal
./lotus client retrieve [CID from import] test.txt # data has to be on chain first
</code></pre>
<h1 id="get-data-on-chain"><a class="header" href="#get-data-on-chain">Get data on chain:</a></h1>
<pre><code>./lotus-miner storage-deals pending-publish --publish-now
./lotus-miner sectors seal 2
./lotus-miner sectors batching precommit --publish-now
./lotus-miner sectors batching commit --publish-now
</code></pre>
<h1 id="retrieve"><a class="header" href="#retrieve">Retrieve:</a></h1>
<pre><code>./lotus client local
./lotus client retrieve --provider t01000 [CID from import] outputfile.txt
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-and-how"><a class="header" href="#what-and-how">What and How?</a></h1>
<p>Fuzzy and Archie are two servers hosted in the ChainSafe office. Both belong to
the Forest team and are running a Ubuntu variant.</p>
<p>Archie and Fuzzy are accessible through a CloudFlare tunnel. Add this to your
SSH config (<code>~/.ssh/config</code>):</p>
<pre><code>Host archie.chainsafe.dev
  ProxyCommand /usr/local/bin/cloudflared access ssh --hostname %h
  User archie

Host fuzzy-forest.chainsafe.dev
  ProxyCommand /usr/local/bin/cloudflared access ssh --hostname %h
  User fuzzy
</code></pre>
<p>If your SSH key has been added to list of authorized keys, you should be able to
directly ssh into <code>archie.chainsafe.dev</code> and <code>fuzzy-forest.chainsafe.dev</code>. If
you key hasn't been added, complain loudly in the #forest slack channel.</p>
<h1 id="archie"><a class="header" href="#archie">Archie</a></h1>
<p>Hardware:</p>
<pre><code>Motherboard:  GIGABYTE B550M
CPU:          AMD Ryzen™ 5 5600G
SSD:          4x SAMSUNG 870 QVO 8 TB
RAM:          G.Skill DIMM 32 GB DDR4-3200
</code></pre>
<p>Archie is currently storing the entire Filecoin graph. In the future, this data
will be served into the Filecoin p2p network.</p>
<h1 id="fuzzy"><a class="header" href="#fuzzy">Fuzzy</a></h1>
<p>Hardware:</p>
<pre><code>Motherboard:  GIGABYTE B550M
CPU:          AMD Ryzen™ 5 5600G
SSD:          1x Seagate FireCuda 530 2 TB
RAM:          G.Skill DIMM 64 GB DDR4-3200
</code></pre>
<p>Fuzzy is meant to run a variety of long-running tasks.</p>
<h2 id="github-action-runner"><a class="header" href="#github-action-runner">Github Action Runner</a></h2>
<p>Fuzzy is using the standard runner with a default configuration. See
https://github.com/actions/runner for details.</p>
<p>The instance can be inspected by running <code>zellij attach runner</code> on the server.
The command to start the runner is <code>cd ~/gc_runner; ./run.sh</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rpc-compatibility"><a class="header" href="#rpc-compatibility">RPC Compatibility</a></h1>
<p>A running Lotus node can be accessed through an RPC interface. The RPC methods
are listed here:</p>
<ul>
<li>V0 methods (stable):
https://github.com/filecoin-project/lotus/blob/master/documentation/en/api-v0-methods.md</li>
<li>V1 methods (unstable):
https://github.com/filecoin-project/lotus/blob/master/documentation/en/api-v1-unstable-methods.md</li>
</ul>
<p>The current status of compatibility can be checked by comparing a running Forest
node with a running Lotus node:</p>
<ol>
<li>Build Lotus with support for Calibnet and sync to HEAD. Run Lotus with
<code>LOTUS_FEVM_ENABLEETHRPC=1</code> to enable the Eth RPC methods.</li>
<li>Run Forest against Calibnet and sync to HEAD.</li>
<li>Run <code>forest-tool api compare</code></li>
</ol>
<p>The output will look like this:</p>
<div class="table-wrapper"><table><thead><tr><th>RPC Method</th><th>Forest</th><th>Lotus</th></tr></thead><tbody>
<tr><td>Filecoin.ChainGetBlock</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.ChainGetGenesis</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.ChainGetMessage (67)</td><td>InternalServerError</td><td>Valid</td></tr>
<tr><td>Filecoin.ChainGetMessagesInTipset</td><td>MissingMethod</td><td>Valid</td></tr>
<tr><td>Filecoin.ChainGetTipSetByHeight</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.ChainHead</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.ChainReadObj</td><td>InvalidResponse</td><td>Valid</td></tr>
<tr><td>Filecoin.Discover</td><td>MissingMethod</td><td>Valid</td></tr>
<tr><td>Filecoin.MpoolPending</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.NetAddrsListen</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.NetInfo</td><td>Valid</td><td>MissingMethod</td></tr>
<tr><td>Filecoin.NetPeers</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.Session</td><td>MissingMethod</td><td>Valid</td></tr>
<tr><td>Filecoin.StartTime</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.StateGetActor</td><td>InternalServerError</td><td>Valid</td></tr>
<tr><td>Filecoin.StateMinerPower (76)</td><td>MissingMethod</td><td>Valid</td></tr>
<tr><td>Filecoin.StateNetworkName</td><td>Valid</td><td>Valid</td></tr>
<tr><td>Filecoin.Version</td><td>Valid</td><td>Valid</td></tr>
</tbody></table>
</div>
<p>If an entry for Lotus is not marked as <code>Valid</code>, this indicates that the Forest
RPC client is buggy and incorrectly communicates with Lotus.</p>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<p>Forest aims at being a drop-in replacement for Lotus and have support for all of
the RPC methods. Note, some methods (like <code>Filecoin.ChainHotGC</code>) are
Lotus-specific and are meaningless in Forest. Such methods should be no-ops in
Forest.</p>
<p>Forest does not yet support mining and none of the mining-related RPC calls will
be implemented in the foreseeable future.</p>
<h2 id="gateway"><a class="header" href="#gateway">Gateway</a></h2>
<p>The <code>lotus-gateway</code> executable is a reverse-proxy that sanitizes RPC calls
before they're forwarded to a Filecoin node. The <code>forest-tool api compare</code>
command will fail if run against a gateway rather than directly against a node.
This means API compatiblity testing has to be done with a local node rather than
<code>api.node.glif.io</code>.</p>
<h2 id="use-mitmproxy"><a class="header" href="#use-mitmproxy">Use <code>mitmproxy</code></a></h2>
<p>Inspecting RPC calls is best done with a reverse proxy. If Lotus listens to port
1234 and Forest listens to port 2345, run the API compatibility tests through
reverse proxies:</p>
<ol>
<li><code>mitmproxy --mode reverse:http://localhost:2345 --listen-port 8080</code></li>
<li><code>mitmproxy --mode reverse:http://localhost:1234 --listen-port 8081</code></li>
<li><code>forest-tool api compare --forest /ip4/127.0.0.1/tcp/8080/http --lotus /ip4/127.0.0.1/tcp/8081/http</code></li>
</ol>
<p>Request / Response pairs will show up in the <code>mitmproxy</code> windows.</p>
<h2 id="adding-a-new-method"><a class="header" href="#adding-a-new-method">Adding a new method</a></h2>
<p>Checklist for adding a new RPC method:</p>
<ol>
<li>Add method name in <code>src/rpc_api/mod.rs</code> and set the access level.</li>
<li>Add request/response data types to <code>src/rpc_api/data_types.rs</code> as needed.</li>
<li>Add <code>RpcRequest</code> in the appropriate file in <code>src/rpc_client/</code>.</li>
<li>Test the method in <code>src/tool/subcommands/api_cmd.rs</code>. The method should show
up as <code>Valid</code> for Lotus and <code>MissingMethod</code> for Forest. Use <code>mitmproxy</code> to
debug.</li>
<li>Implement Forest endpoint in <code>src/rpc/</code>, add it to the method list in
<code>src/rpc/mod.rs</code></li>
<li>Verify that the test from step 4 shows <code>Valid</code> for Forest.</li>
</ol>
<h2 id="creating-own-miner-for-tests"><a class="header" href="#creating-own-miner-for-tests">Creating own miner for tests</a></h2>
<p>Use commands along the lines of the following script to create a miner for
testing. Note that the <code>miner create</code> will take a while to complete.</p>
<pre><code class="language-bash">#!/bin/bash
# Owner
# The owner keypair is provided by the miner ahead of registration and its public key associated with the miner address.
# The owner keypair can be used to administer a miner and withdraw funds.
OWNER=$(lotus wallet new bls)
WORKER=$(lotus wallet new bls)
SENDER=$(lotus wallet new bls)

# print the owner address and order the user to send FIL from faucet to it. Wait for the confirmation from the user.
echo "Owner: $OWNER"
echo "Please send some FIL to the owner address and press enter to continue. Ensure that that the transaction is confirmed."
read

# Send some FIL to the worker and sender from the owner address
lotus send --from $OWNER $WORKER 10
lotus send --from $OWNER $SENDER 10

echo "Wait till the funds are confirmed and press enter to continue."
read

lotus-shed miner create $SENDER $OWNER $WORKER 32GiB
</code></pre>
<p>Afterwards, use the <code>lotus wallet export</code> and <code>lotus wallet import</code> commands to
persist and restore the keys.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="notes-and-sketches"><a class="header" href="#notes-and-sketches">Notes and sketches</a></h1>
<p>The notes found here may be out of date.</p>
<div style="break-before: page; page-break-before: always;"></div><p>Date: 2023-10-21</p>
<p><code>ChainMuxer</code> state transitions:</p>
<pre><code class="language-mermaid">flowchart TD
    A[Idle]
    B[Connect]
    C[Bootstrap]
    D[Follow]

    A --&gt;|sync| B
    A --&gt;|skip| D
    B --&gt;|behind| C
    B --&gt;|in-sync| D
    D --&gt;|on-error| A
    C --&gt; A
</code></pre>
<p>Once the <code>ChainMuxer</code> is in <code>follow</code> mode, it passes control to the
<code>TipsetProcessor</code>. A typical start-up sequence looks like this:</p>
<ol>
<li><code>idle</code> state: Immediately switch to <code>connect</code> state.</li>
<li><code>connect</code> state: Wait for 5 tipsets from peers. If we're within 1 epoch of
the heaviest seen tipset, switch to <code>follow</code> state. Otherwise, switch to
<code>bootstrap</code> state.</li>
<li><code>bootstrap</code> state: Fetch tipsets between the heaviest seen tipset and the
last validated tipset. Validate all of those tipsets and return to <code>idle</code>
state.</li>
<li><code>follow</code> state: Pass control to the <code>TipsetProcessor</code> state machine.</li>
</ol>
<p><code>TipsetProcessor</code> state transitions:</p>
<pre><code class="language-mermaid">flowchart TD
    A[Idle]
    B[FindRange]
    C[SyncRange]

    A --&gt;|new tipset group| B
    B --&gt; C
    C --&gt; A
    C --&gt; B
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
